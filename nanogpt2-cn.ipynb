{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-02T19:02:35.724003Z","iopub.execute_input":"2026-02-02T19:02:35.724773Z","iopub.status.idle":"2026-02-02T19:02:36.019264Z","shell.execute_reply.started":"2026-02-02T19:02:35.724742Z","shell.execute_reply":"2026-02-02T19:02:36.018665Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# Kaggle Mini GPT-2 ä¸­æ–‡é¢„è®­ç»ƒ","metadata":{}},{"cell_type":"markdown","source":"**ğŸ“‹ ç›®æ ‡è§„æ ¼**\n\næŒ‡æ ‡\tç›®æ ‡å€¼\n\næ¨¡å‹æ¶æ„\tGPT-2 (6 å±‚, 768 hidden, 12 heads) â‰ˆ 67.5M å‚æ•°\n\nè®­ç»ƒæ•°æ®\tä¸­æ–‡ç»´åŸºç™¾ç§‘ + çŸ¥ä¹ (~625M tokens)\n\nContext é•¿åº¦\t1024 tokens\n\nè®­ç»ƒç¯å¢ƒ\tKaggle Notebook, GPU T4 x2, 12h é™æ—¶\n\næœ€ç»ˆ Loss\t< 4.0 (ç†æƒ³ < 3.5)\n\néƒ¨ç½²å¹³å°\tHuggingFace Spaces (Gradio, CPU)","metadata":{}},{"cell_type":"markdown","source":"**æ ¸å¿ƒä¼˜åŒ–**\n\nä¼˜åŒ–é¡¹\t               æ”¶ç›Š\t           ä»£ç ä½ç½®\n\ntorch.compile()\t   é€Ÿåº¦ +50-100%\t       Cell 5 æ¨¡å‹åˆå§‹åŒ–\n\nSDPA Attention\t   é€Ÿåº¦ +10-30%\t       Cell 5 config\n\nLiger LayerNorm\t  LayerNorm +30%\t   Cell 5 patch\n\nLiger FusedLinearCrossEntropy\tæ˜¾å­˜ -6080%, é€Ÿåº¦ +50100%\tCell 7 LigerTrainer\n\n8-bit AdamW\t       ä¼˜åŒ–å™¨æ˜¾å­˜ -75%\t   Cell 7 è®­ç»ƒå‚æ•°\n\næ•°æ®åŠ è½½ä¼˜åŒ–\t       ååé‡ +10-30%\t   Cell 7 è®­ç»ƒå‚æ•°\n\nFP16 æ··åˆç²¾åº¦\t    æ˜¾å­˜å‡åŠ\t           Cell 7 è®­ç»ƒå‚æ•°","metadata":{}},{"cell_type":"markdown","source":"**T4 ç¡¬ä»¶é™åˆ¶**\n\nâŒ ä¸æ”¯æŒ BF16ï¼ˆåªèƒ½ç”¨ FP16ï¼‰\n\nâŒ ä¸æ”¯æŒ Flash Attention 2.x\n\nâœ… æ”¯æŒ Triton kernels (Liger Kernel)\n\nâœ… æ¯å¡ 15GBï¼Œä¼˜åŒ–åå¯ç”¨æ›´å¤š","metadata":{}},{"cell_type":"markdown","source":"# ğŸ§± ç¬¬ä¸€é˜¶æ®µï¼šç¯å¢ƒé…ç½®ä¸æ•°æ®å‡†å¤‡","metadata":{}},{"cell_type":"markdown","source":"**1.1 Kaggle Notebook åˆå§‹åŒ–**","metadata":{}},{"cell_type":"markdown","source":"åœ¨ Kaggle æ–°å»º Notebook æ—¶ï¼š\n\nAccelerator: GPU T4 x2\n\nInternet: On\n\nPersistence: Enable Files persistence (é‡è¦ï¼)","metadata":{}},{"cell_type":"code","source":"# === Cell 1: ç¯å¢ƒè¯Šæ–­ä¸åº“å®‰è£… ===\nimport os\n# å¯ç”¨åŒ GPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n# æ£€æŸ¥ GPU å¯ç”¨æ€§\n!nvidia-smi\n# å®‰è£…ä¾èµ–ï¼ˆä¸æŒ‡å®šç‰ˆæœ¬ï¼Œä½¿ç”¨ Kaggle é¢„è£…çš„å…¼å®¹ç‰ˆæœ¬ï¼‰\n!pip install -q \\\n    transformers datasets accelerate \\\n    huggingface_hub sentencepiece tokenizers \\\n    bitsandbytes \\\n    liger-kernel\n# éªŒè¯å®‰è£…\nimport torch\nprint(f\"PyTorch: {torch.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nprint(f\"GPU count: {torch.cuda.device_count()}\")\nfor i in range(torch.cuda.device_count()):\n    print(f\"  GPU {i}: {torch.cuda.get_device_name(i)}\")\n# æ³¨æ„ï¼šKaggle ç¯å¢ƒä¸æ”¯æŒ DDPï¼ŒTrainer ä¼šè‡ªåŠ¨ä½¿ç”¨ DataParallel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-03T05:22:39.120949Z","iopub.execute_input":"2026-02-03T05:22:39.121742Z","iopub.status.idle":"2026-02-03T05:22:48.287828Z","shell.execute_reply.started":"2026-02-03T05:22:39.121712Z","shell.execute_reply":"2026-02-03T05:22:48.287051Z"}},"outputs":[{"name":"stdout","text":"Tue Feb  3 05:22:39 2026       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 580.105.08             Driver Version: 580.105.08     CUDA Version: 13.0     |\n+-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   37C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   38C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n\n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m230.6/230.6 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hPyTorch: 2.8.0+cu126\nCUDA available: True\nGPU count: 2\n  GPU 0: Tesla T4\n  GPU 1: Tesla T4\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"TIP\né‡è¦ï¼šä¸è¦æŒ‡å®šç‰ˆæœ¬å·ï¼Kaggle ç¯å¢ƒä¼šè‡ªåŠ¨é€‰æ‹©å…¼å®¹ç‰ˆæœ¬ã€‚","metadata":{}},{"cell_type":"markdown","source":"**1.2 HuggingFace ç™»å½•**","metadata":{}},{"cell_type":"code","source":"# === Cell 2: HuggingFace Hub ç™»å½• ===\nfrom huggingface_hub import notebook_login, HfFolder\n# æ–¹æ³• 1: äº¤äº’å¼ç™»å½• (éœ€è¦æ‰‹åŠ¨è¾“å…¥ token)\nnotebook_login()\n# æ–¹æ³• 2: éäº¤äº’å¼ (ç”¨äº \"Save & Run All\" æ¨¡å¼)\n# import os\n# os.environ[\"HF_TOKEN\"] = \"hf_your_token_here\"\n# HfFolder.save_token(os.environ[\"HF_TOKEN\"])\n# éªŒè¯ç™»å½•çŠ¶æ€\nfrom huggingface_hub import whoami\ntry:\n    user_info = whoami()\n    HF_USERNAME = user_info[\"name\"]\n    print(f\"âœ… å·²ç™»å½•ä¸º: {HF_USERNAME}\")\nexcept Exception as e:\n    print(f\"âŒ ç™»å½•å¤±è´¥: {e}\")\n    HF_USERNAME = \"your_username\"  # éœ€æ‰‹åŠ¨å¡«å†™","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-03T05:23:07.748319Z","iopub.execute_input":"2026-02-03T05:23:07.748885Z","iopub.status.idle":"2026-02-03T05:23:07.844697Z","shell.execute_reply.started":"2026-02-03T05:23:07.748860Z","shell.execute_reply":"2026-02-03T05:23:07.844125Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0310ab75235041299b0bbcaeee6f8894"}},"metadata":{}},{"name":"stdout","text":"âœ… å·²ç™»å½•ä¸º: Wilsonwin\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"**IMPORTANT**\nå…³é”®æç¤º: Token å¿…é¡»å…·æœ‰ Write æƒé™æ‰èƒ½ä¸Šä¼ æ¨¡å‹ã€‚åœ¨ HuggingFace Settings â†’ Access Tokens ä¸­åˆ›å»ºã€‚","metadata":{}},{"cell_type":"markdown","source":"**1.3 æ•°æ®è·å–ä¸é¢„å¤„ç†(ç»´åŸºç™¾ç§‘ + çŸ¥ä¹)**","metadata":{}},{"cell_type":"code","source":"# === Cell 3: å¤šæ•°æ®é›†åŠ è½½ï¼ˆæ¨èï¼‰===\nfrom datasets import load_dataset, concatenate_datasets, Dataset\nimport os\nprint(\"ğŸ“¥ æ­£åœ¨ä¸‹è½½å¤šä¸ªæ•°æ®é›†...\")\n# === 1. åŠ è½½ç»´åŸºç™¾ç§‘ï¼ˆå®Œæ•´ï¼‰===\nprint(\"   [1/2] åŠ è½½ç»´åŸºç™¾ç§‘...\")\nwiki = load_dataset(\n    \"pleisto/wikipedia-cn-20230720-filtered\",\n    split=\"train\",  # å®Œæ•´æ•°æ®\n)\nprint(f\"   âœ… ç»´åŸºç™¾ç§‘: {len(wiki)} æ¡\")\n# === 2. åŠ è½½çŸ¥ä¹é«˜èµå›ç­” ===\nprint(\"   [2/2] åŠ è½½çŸ¥ä¹...\")\nzhihu = load_dataset(\n    \"wangrui6/Zhihu-KOL\",\n    split=\"train\",\n)\nprint(f\"   âœ… çŸ¥ä¹: {len(zhihu)} æ¡\")\n# === 3. ç»Ÿä¸€å­—æ®µåå¹¶åˆå¹¶ ===\n# ç»´åŸºç™¾ç§‘å­—æ®µ: completion\n# çŸ¥ä¹å­—æ®µ: INSTRUCTION, RESPONSE (éœ€è¦åˆå¹¶)\ndef process_wiki(example):\n    return {\"text\": example[\"completion\"]}\ndef process_zhihu(example):\n    # åˆå¹¶é—®é¢˜å’Œå›ç­”\n    text = f\"{example['INSTRUCTION']}\\n{example['RESPONSE']}\"\n    return {\"text\": text}\nprint(\"ğŸ”„ æ­£åœ¨å¤„ç†æ•°æ®æ ¼å¼...\")\nwiki_processed = wiki.map(process_wiki, remove_columns=wiki.column_names, num_proc=4)\nzhihu_processed = zhihu.map(process_zhihu, remove_columns=zhihu.column_names, num_proc=4)\n# åˆå¹¶æ•°æ®é›†\ndataset = concatenate_datasets([wiki_processed, zhihu_processed])\ndataset = dataset.shuffle(seed=42)\nprint(f\"\\nâœ… æ•°æ®é›†åˆå¹¶å®Œæˆ!\")\nprint(f\"   ç»´åŸºç™¾ç§‘: {len(wiki)} æ¡\")\nprint(f\"   çŸ¥ä¹: {len(zhihu)} æ¡\")\nprint(f\"   åˆè®¡: {len(dataset)} æ¡\")\nprint(f\"   ç¤ºä¾‹: {dataset[0]['text'][:100]}...\")\n# === 4. å¯¼å‡ºä¸ºçº¯æ–‡æœ¬ä¾›åˆ†è¯å™¨è®­ç»ƒï¼ˆä¼˜åŒ–ç‰ˆï¼‰===\nCORPUS_FILE = \"/kaggle/working/combined_corpus.txt\"\nprint(\"ğŸ“ æ­£åœ¨å¯¼å‡ºçº¯æ–‡æœ¬ï¼ˆä¼˜åŒ–ç‰ˆï¼‰...\")\n# ä½¿ç”¨ map + æ‰¹é‡å†™å…¥ï¼Œæ¯” for å¾ªç¯å¿« 5-10 å€\ndef filter_short(example):\n    return len(example[\"text\"].strip()) > 50\n# è¿‡æ»¤çŸ­æ–‡æœ¬\nfiltered = dataset.filter(filter_short, num_proc=4)\nprint(f\"   è¿‡æ»¤å: {len(filtered)} æ¡ (åŸ {len(dataset)} æ¡)\")\n# æ‰¹é‡å†™å…¥æ–‡ä»¶\nBATCH_SIZE = 10000\nwith open(CORPUS_FILE, \"w\", encoding=\"utf-8\") as f:\n    for i in range(0, len(filtered), BATCH_SIZE):\n        batch = filtered[i:i+BATCH_SIZE][\"text\"]\n        f.write(\"\\n\".join(text.strip() for text in batch) + \"\\n\")\n        if (i // BATCH_SIZE) % 10 == 0:\n            print(f\"   å·²å¯¼å‡º {min(i+BATCH_SIZE, len(filtered))}/{len(filtered)}...\")\n# ç»Ÿè®¡è¯­æ–™è§„æ¨¡\nfile_size_mb = os.path.getsize(CORPUS_FILE) / (1024 * 1024)\nwith open(CORPUS_FILE, \"r\", encoding=\"utf-8\") as f:\n    line_count = sum(1 for _ in f)\nprint(f\"âœ… è¯­æ–™å¯¼å‡ºå®Œæˆ: {file_size_mb:.1f} MB, {line_count} è¡Œ\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-03T05:23:14.674362Z","iopub.execute_input":"2026-02-03T05:23:14.674670Z","iopub.status.idle":"2026-02-03T05:25:12.661162Z","shell.execute_reply.started":"2026-02-03T05:23:14.674643Z","shell.execute_reply":"2026-02-03T05:25:12.660159Z"}},"outputs":[{"name":"stdout","text":"ğŸ“¥ æ­£åœ¨ä¸‹è½½å¤šä¸ªæ•°æ®é›†...\n   [1/2] åŠ è½½ç»´åŸºç™¾ç§‘...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9223ef23cbaa4763aaffe526d8eda614"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"wikipedia-cn-20230720-filtered.json:   0%|          | 0.00/524M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d4e14a49284461a8c6ec23de7f75c4a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3d56b2e74ec43a2ab046e98a3023b18"}},"metadata":{}},{"name":"stdout","text":"   âœ… ç»´åŸºç™¾ç§‘: 254547 æ¡\n   [2/2] åŠ è½½çŸ¥ä¹...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2600f2e855d4cf08d191cb1e0931196"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/train-00000-of-00005-a1278ede4e8c5c(â€¦):   0%|          | 0.00/306M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f297cfdaa52d4905b6083ae8f3b90b49"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/train-00001-of-00005-1fc2da944397e9(â€¦):   0%|          | 0.00/303M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1303fc6cd4bc4bb494a07ac96617cb79"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/train-00002-of-00005-68ced004a14581(â€¦):   0%|          | 0.00/300M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4652e1ed0cf0411d97cea61b7b2c05cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/train-00003-of-00005-1dae36b67c1216(â€¦):   0%|          | 0.00/292M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca7c64b0802b4296a5d1d743884216a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/train-00004-of-00005-c374cc9fbda9fd(â€¦):   0%|          | 0.00/299M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b158e7bed949495d97d6c8b26a3804ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/1006218 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d7fefd57909452dac90dd6fdd4e8087"}},"metadata":{}},{"name":"stdout","text":"   âœ… çŸ¥ä¹: 1006218 æ¡\nğŸ”„ æ­£åœ¨å¤„ç†æ•°æ®æ ¼å¼...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/254547 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45e2d9601bdc426b840a3483720b2b28"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/1006218 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7a04889ac064f8e8f929aa215d07cde"}},"metadata":{}},{"name":"stdout","text":"\nâœ… æ•°æ®é›†åˆå¹¶å®Œæˆ!\n   ç»´åŸºç™¾ç§‘: 254547 æ¡\n   çŸ¥ä¹: 1006218 æ¡\n   åˆè®¡: 1260765 æ¡\n   ç¤ºä¾‹: å¦‚ä½•çœ‹å¾…è…¾è®¯å°† Steam ç½‘ç«™æ¶æ„åˆ—ä¸ºå±é™©ç½‘ç«™ï¼Ÿ\nä¸æ˜¯è¿™ä¸ªç½‘ç«™å¯¹ä½ æœ‰å±é™©ï¼Œæ˜¯ä½ ä¸Šè¿™ä¸ªç½‘ç«™å¯¹è…¾è®¯æœ‰å±é™©ï¼Œæ‰€ä»¥å®ƒè¯´çš„æ²¡é”™...\nğŸ“ æ­£åœ¨å¯¼å‡ºçº¯æ–‡æœ¬ï¼ˆä¼˜åŒ–ç‰ˆï¼‰...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Filter (num_proc=4):   0%|          | 0/1260765 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9a550edf63f4d419abae339faefa778"}},"metadata":{}},{"name":"stdout","text":"   è¿‡æ»¤å: 1137084 æ¡ (åŸ 1260765 æ¡)\n   å·²å¯¼å‡º 10000/1137084...\n   å·²å¯¼å‡º 110000/1137084...\n   å·²å¯¼å‡º 210000/1137084...\n   å·²å¯¼å‡º 310000/1137084...\n   å·²å¯¼å‡º 410000/1137084...\n   å·²å¯¼å‡º 510000/1137084...\n   å·²å¯¼å‡º 610000/1137084...\n   å·²å¯¼å‡º 710000/1137084...\n   å·²å¯¼å‡º 810000/1137084...\n   å·²å¯¼å‡º 910000/1137084...\n   å·²å¯¼å‡º 1010000/1137084...\n   å·²å¯¼å‡º 1110000/1137084...\nâœ… è¯­æ–™å¯¼å‡ºå®Œæˆ: 2451.3 MB, 5502872 è¡Œ\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"**WARNING**\n\nKaggle é™åˆ¶æ³¨æ„äº‹é¡¹ï¼š\n\nåˆå¹¶æ•°æ®é›†çº¦ 2.4GBï¼Œä¸‹è½½éœ€è¦ 10-15 åˆ†é’Ÿ\nè®­ç»ƒæ—¶é—´çº¦ 8-10 å°æ—¶ï¼Œæ¥è¿‘ 12 å°æ—¶é™åˆ¶\nå»ºè®®å¯ç”¨ hub_strategy=\"checkpoint\" ç¡®ä¿ä¸­é€”ä¿å­˜","metadata":{}},{"cell_type":"markdown","source":"# ğŸ”¤ ç¬¬äºŒé˜¶æ®µï¼šSentencePiece åˆ†è¯å™¨è®­ç»ƒ","metadata":{}},{"cell_type":"markdown","source":"**2.1 ä¸ºä»€ä¹ˆé€‰æ‹© SentencePiece Unigram**","metadata":{}},{"cell_type":"markdown","source":"ç‰¹æ€§\tByteLevelBPE\tSentencePiece Unigram\n\nä¸­æ–‡å­—ç¬¦å¤„ç†\tæŒ‰ UTF-8 å­—èŠ‚åˆ‡åˆ† (è†¨èƒ€ 3x)\tç›´æ¥å¤„ç† Unicode\n\nè¯è¡¨æ•ˆç‡\tä½ (éœ€è¦å¤§è¯è¡¨)\té«˜\n\nåºåˆ—é•¿åº¦\té•¿\tçŸ­ (~30-50% å‹ç¼©)\n\næ— ç©ºæ ¼è¯­è¨€æ”¯æŒ\tä¸€èˆ¬\tä¼˜ç§€ (ä¸“é—¨è®¾è®¡)","metadata":{}},{"cell_type":"markdown","source":"**2.2 åˆ†è¯å™¨è®­ç»ƒ**","metadata":{}},{"cell_type":"code","source":"# === Cell 4: è®­ç»ƒ SentencePiece åˆ†è¯å™¨ï¼ˆä¼˜åŒ–ç‰ˆï¼‰===\nimport sentencepiece as spm\nimport os\nimport random\nfrom concurrent.futures import ProcessPoolExecutor, as_completed\nimport multiprocessing\nMODEL_PREFIX = \"/kaggle/working/chinese_sp\"\nVOCAB_SIZE = 32000\nSAMPLE_SIZE = 500000  # 50 ä¸‡å¥è®­ç»ƒè¯è¡¨\n# === å¤šè¿›ç¨‹é‡‡æ ·å¯¼å‡ºè¯­æ–™ ===\nprint(f\"ğŸ“ é‡‡æ · {SAMPLE_SIZE} å¥ç”¨äºåˆ†è¯å™¨è®­ç»ƒ...\")\nprint(f\"   CPU æ ¸å¿ƒæ•°: {multiprocessing.cpu_count()}\")\nrandom.seed(42)\nindices = list(range(len(dataset)))\nrandom.shuffle(indices)\nsampled_indices = indices[:SAMPLE_SIZE]\n# ä½¿ç”¨ datasets çš„ select + map å¹¶è¡Œå¤„ç†\nsampled_dataset = dataset.select(sampled_indices)\ndef filter_text(example):\n    text = example[\"text\"].strip()\n    if 50 < len(text) < 5000:\n        return {\"text\": text, \"valid\": True}\n    return {\"text\": \"\", \"valid\": False}\n# å¤šè¿›ç¨‹å¤„ç†\nprint(\"ğŸ”„ å¹¶è¡Œå¤„ç†æ–‡æœ¬...\")\nprocessed = sampled_dataset.map(\n    filter_text,\n    num_proc=multiprocessing.cpu_count(),\n    desc=\"Processing\"\n)\n# è¿‡æ»¤æœ‰æ•ˆæ–‡æœ¬å¹¶å†™å…¥\nvalid_texts = [ex[\"text\"] for ex in processed if ex[\"valid\"]]\nprint(f\"âœ… æœ‰æ•ˆæ–‡æœ¬: {len(valid_texts)} å¥\")\nwith open(CORPUS_FILE, \"w\", encoding=\"utf-8\") as f:\n    f.write(\"\\n\".join(valid_texts))\ncorpus_size_mb = os.path.getsize(CORPUS_FILE) / 1024 / 1024\nprint(f\"âœ… è¯­æ–™å¯¼å‡ºå®Œæˆ: {corpus_size_mb:.1f} MB\")\n# è®­ç»ƒåˆ†è¯å™¨\nimport time\nprint(\"=\" * 50)\nprint(\"ğŸ”¤ å¼€å§‹è®­ç»ƒåˆ†è¯å™¨...\")\nprint(f\"   è¯è¡¨å¤§å°: {VOCAB_SIZE}\")\nprint(f\"   è®­ç»ƒå¥æ•°: {len(valid_texts)}\")\nprint(f\"   CPU çº¿ç¨‹: {os.cpu_count() or 4}\")\nprint(\"   â³ é¢„è®¡è€—æ—¶ 2-5 åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…...\")\nprint(\"=\" * 50)\nstart_time = time.time()\nspm.SentencePieceTrainer.train(\n    input=CORPUS_FILE,\n    model_prefix=MODEL_PREFIX,\n    vocab_size=VOCAB_SIZE,\n    model_type=\"unigram\",\n    character_coverage=0.9995,\n    \n    # === é€Ÿåº¦ä¼˜åŒ–å‚æ•° ===\n    input_sentence_size=500000,\n    shuffle_input_sentence=True,\n    max_sentence_length=1024,\n    train_extremely_large_corpus=False,\n    \n    # ç‰¹æ®Š Token\n    pad_id=0, unk_id=1, bos_id=2, eos_id=3,\n    pad_piece=\"<pad>\", unk_piece=\"<unk>\",\n    bos_piece=\"<s>\", eos_piece=\"</s>\",\n    \n    # æ€§èƒ½ä¼˜åŒ–\n    num_threads=os.cpu_count() or 4,\n    normalization_rule_name=\"nmt_nfkc_cf\",\n    split_by_unicode_script=True,\n    split_by_number=True,\n)\nelapsed = time.time() - start_time\nprint(\"=\" * 50)\nprint(f\"âœ… åˆ†è¯å™¨è®­ç»ƒå®Œæˆ! è€—æ—¶: {elapsed:.1f} ç§’\")\nprint(f\"   æ¨¡å‹æ–‡ä»¶: {MODEL_PREFIX}.model\")\nprint(f\"   è¯è¡¨æ–‡ä»¶: {MODEL_PREFIX}.vocab\")\n# éªŒè¯åˆ†è¯å™¨\nsp = spm.SentencePieceProcessor(model_file=f\"{MODEL_PREFIX}.model\")\ntest_text = \"äººå·¥æ™ºèƒ½æ­£åœ¨æ”¹å˜ä¸–ç•Œ\"\ntokens = sp.encode(test_text, out_type=str)\nprint(f\"   æµ‹è¯•åˆ†è¯: {test_text} â†’ {tokens}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-03T05:25:17.174475Z","iopub.execute_input":"2026-02-03T05:25:17.174815Z","iopub.status.idle":"2026-02-03T05:29:05.533129Z","shell.execute_reply.started":"2026-02-03T05:25:17.174784Z","shell.execute_reply":"2026-02-03T05:29:05.532139Z"}},"outputs":[{"name":"stdout","text":"ğŸ“ é‡‡æ · 500000 å¥ç”¨äºåˆ†è¯å™¨è®­ç»ƒ...\n   CPU æ ¸å¿ƒæ•°: 4\nğŸ”„ å¹¶è¡Œå¤„ç†æ–‡æœ¬...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Processing (num_proc=4):   0%|          | 0/500000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9473688e62964524b834ad147a81eed4"}},"metadata":{}},{"name":"stdout","text":"âœ… æœ‰æ•ˆæ–‡æœ¬: 442856 å¥\nâœ… è¯­æ–™å¯¼å‡ºå®Œæˆ: 796.0 MB\n==================================================\nğŸ”¤ å¼€å§‹è®­ç»ƒåˆ†è¯å™¨...\n   è¯è¡¨å¤§å°: 32000\n   è®­ç»ƒå¥æ•°: 442856\n   CPU çº¿ç¨‹: 4\n   â³ é¢„è®¡è€—æ—¶ 2-5 åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…...\n==================================================\n==================================================\nâœ… åˆ†è¯å™¨è®­ç»ƒå®Œæˆ! è€—æ—¶: 192.1 ç§’\n   æ¨¡å‹æ–‡ä»¶: /kaggle/working/chinese_sp.model\n   è¯è¡¨æ–‡ä»¶: /kaggle/working/chinese_sp.vocab\n   æµ‹è¯•åˆ†è¯: äººå·¥æ™ºèƒ½æ­£åœ¨æ”¹å˜ä¸–ç•Œ â†’ ['â–', 'äººå·¥æ™ºèƒ½', 'æ­£åœ¨', 'æ”¹å˜', 'ä¸–ç•Œ']\n","output_type":"stream"},{"name":"stderr","text":"sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \ntrainer_spec {\n  input: /kaggle/working/combined_corpus.txt\n  input_format: \n  model_prefix: /kaggle/working/chinese_sp\n  model_type: UNIGRAM\n  vocab_size: 32000\n  self_test_sample_size: 0\n  character_coverage: 0.9995\n  input_sentence_size: 500000\n  shuffle_input_sentence: 1\n  seed_sentencepiece_size: 1000000\n  shrinking_factor: 0.75\n  max_sentence_length: 1024\n  num_threads: 4\n  num_sub_iterations: 2\n  max_sentencepiece_length: 16\n  split_by_unicode_script: 1\n  split_by_number: 1\n  split_by_whitespace: 1\n  split_digits: 0\n  pretokenization_delimiter: \n  treat_whitespace_as_suffix: 0\n  allow_whitespace_only_pieces: 0\n  required_chars: \n  byte_fallback: 0\n  vocabulary_output_piece_score: 1\n  train_extremely_large_corpus: 0\n  seed_sentencepieces_file: \n  hard_vocab_limit: 1\n  use_all_vocab: 0\n  unk_id: 1\n  bos_id: 2\n  eos_id: 3\n  pad_id: 0\n  unk_piece: <unk>\n  bos_piece: <s>\n  eos_piece: </s>\n  pad_piece: <pad>\n  unk_surface:  â‡ \n  enable_differential_privacy: 0\n  differential_privacy_noise_level: 0\n  differential_privacy_clipping_threshold: 0\n}\nnormalizer_spec {\n  name: nmt_nfkc_cf\n  add_dummy_prefix: 1\n  remove_extra_whitespaces: 1\n  escape_whitespaces: 1\n  normalization_rule_tsv: \n}\ndenormalizer_spec {}\ntrainer_interface.cc(355) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\ntrainer_interface.cc(186) LOG(INFO) Loading corpus: /kaggle/working/combined_corpus.txt\ntrainer_interface.cc(382) LOG(WARNING) Found too long line (3184 > 1024).\ntrainer_interface.cc(384) LOG(WARNING) Too long lines are skipped in the training.\ntrainer_interface.cc(385) LOG(WARNING) The maximum length can be changed with --max_sentence_length=<size> flag.\ntrainer_interface.cc(148) LOG(INFO) Loaded 1000000 lines\ntrainer_interface.cc(413) LOG(INFO) Sampled 500000 sentences from 1887793 sentences.\ntrainer_interface.cc(418) LOG(INFO) Skipped 162785 too long sentences.\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <pad>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <unk>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: <s>\ntrainer_interface.cc(427) LOG(INFO) Adding meta_piece: </s>\ntrainer_interface.cc(432) LOG(INFO) Normalizing sentences...\ntrainer_interface.cc(541) LOG(INFO) all chars count=26972166\ntrainer_interface.cc(552) LOG(INFO) Done: 99.95% characters are covered.\ntrainer_interface.cc(562) LOG(INFO) Alphabet size=7075\ntrainer_interface.cc(563) LOG(INFO) Final character coverage=0.9995\ntrainer_interface.cc(594) LOG(INFO) Done! preprocessed 499894 sentences.\nunigram_model_trainer.cc(265) LOG(INFO) Making suffix array...\nunigram_model_trainer.cc(269) LOG(INFO) Extracting frequent sub strings... node_num=7914943\nunigram_model_trainer.cc(312) LOG(INFO) Initialized 1007075 seed sentencepieces\ntrainer_interface.cc(600) LOG(INFO) Tokenizing input sentences with whitespace: 499894\ntrainer_interface.cc(611) LOG(INFO) Done! 679445\nunigram_model_trainer.cc(602) LOG(INFO) Using 679445 sentences for EM training\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=687115 obj=127.66 num_tokens=11407543 num_tokens/piece=16.6021\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=609879 obj=119.348 num_tokens=11506856 num_tokens/piece=18.8674\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=457220 obj=119.547 num_tokens=11726717 num_tokens/piece=25.6479\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=456698 obj=119.238 num_tokens=11748185 num_tokens/piece=25.7242\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=342503 obj=120.271 num_tokens=12067981 num_tokens/piece=35.2347\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=342489 obj=119.861 num_tokens=12082567 num_tokens/piece=35.2787\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=256859 obj=121.426 num_tokens=12462826 num_tokens/piece=48.5201\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=256852 obj=120.934 num_tokens=12472837 num_tokens/piece=48.5604\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=192639 obj=122.86 num_tokens=12864669 num_tokens/piece=66.7812\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=192638 obj=122.352 num_tokens=12872186 num_tokens/piece=66.8206\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=144477 obj=124.577 num_tokens=13281956 num_tokens/piece=91.9313\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=144477 obj=124.075 num_tokens=13287165 num_tokens/piece=91.9673\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=108357 obj=126.485 num_tokens=13715370 num_tokens/piece=126.576\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=108357 obj=125.99 num_tokens=13717667 num_tokens/piece=126.597\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=81267 obj=128.538 num_tokens=14167727 num_tokens/piece=174.336\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=81267 obj=128.042 num_tokens=14169073 num_tokens/piece=174.352\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=60950 obj=130.679 num_tokens=14636383 num_tokens/piece=240.138\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=60950 obj=130.167 num_tokens=14637039 num_tokens/piece=240.148\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=45712 obj=132.932 num_tokens=15135034 num_tokens/piece=331.095\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=45712 obj=132.377 num_tokens=15135915 num_tokens/piece=331.115\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=35200 obj=135.057 num_tokens=15629401 num_tokens/piece=444.017\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=35200 obj=134.505 num_tokens=15631344 num_tokens/piece=444.072\ntrainer_interface.cc(689) LOG(INFO) Saving model: /kaggle/working/chinese_sp.model\ntrainer_interface.cc(701) LOG(INFO) Saving vocabs: /kaggle/working/chinese_sp.vocab\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"WARNING\n\nå¸¸è§é”™è¯¯: sentencepiece_trainer.cc:177 Vocab size too small åŸå› : è¯­æ–™å¤ªå°æ— æ³•æ”¯æ’‘å¤§è¯è¡¨ è§£å†³: é™ä½ vocab_size åˆ° 16000 æˆ–å¢åŠ è¯­æ–™","metadata":{}},{"cell_type":"markdown","source":"**2.3 è½¬æ¢ä¸º HuggingFace æ ¼å¼**","metadata":{}},{"cell_type":"code","source":"# === Cell 5: è½¬æ¢åˆ†è¯å™¨ä¸º HuggingFace æ ¼å¼ï¼ˆå¸¦ç¼“å­˜æ£€æµ‹ï¼‰===\nimport sentencepiece as spm\nfrom transformers import PreTrainedTokenizerFast, LlamaTokenizerFast, AutoTokenizer\nimport json\nimport os\nimport shutil\n\nTOKENIZER_DIR = \"/kaggle/working/tokenizer\"\n\n# === ç¼“å­˜æ£€æµ‹ï¼šå¦‚æœ HF æ ¼å¼åˆ†è¯å™¨å·²å­˜åœ¨åˆ™è·³è¿‡ ===\nif os.path.exists(f\"{TOKENIZER_DIR}/tokenizer.json\"):\n    print(\"=\" * 50)\n    print(\"âœ… æ£€æµ‹åˆ°å·²è½¬æ¢çš„ HuggingFace åˆ†è¯å™¨ï¼Œè·³è¿‡è½¬æ¢\")\n    print(f\"   ç›®å½•: {TOKENIZER_DIR}\")\n    tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_DIR)\n    print(f\"   è¯è¡¨å¤§å°: {len(tokenizer)}\")\n    # æµ‹è¯•åˆ†è¯\n    test_text = \"äººå·¥æ™ºèƒ½æ˜¯æœªæ¥ç§‘æŠ€å‘å±•çš„é‡è¦æ–¹å‘ã€‚\"\n    tokens = tokenizer.tokenize(test_text)\n    print(f\"   æµ‹è¯•: {test_text[:20]}... â†’ {tokens[:5]}...\")\n    print(\"=\" * 50)\nelse:\n    # === è½¬æ¢åˆ†è¯å™¨ ===\n    os.makedirs(TOKENIZER_DIR, exist_ok=True)\n    \n    # å¤åˆ¶æ¨¡å‹æ–‡ä»¶\n    shutil.copy(f\"{MODEL_PREFIX}.model\", f\"{TOKENIZER_DIR}/spiece.model\")\n    shutil.copy(f\"{MODEL_PREFIX}.vocab\", f\"{TOKENIZER_DIR}/spiece.vocab\")\n    \n    # åˆ›å»º tokenizer_config.json\n    tokenizer_config = {\n        \"bos_token\": \"<s>\",\n        \"eos_token\": \"</s>\",\n        \"unk_token\": \"<unk>\",\n        \"pad_token\": \"<pad>\",\n        \"sp_model_kwargs\": {},\n        \"add_bos_token\": False,\n        \"add_eos_token\": False,\n        \"model_max_length\": 512,\n        \"tokenizer_class\": \"PreTrainedTokenizerFast\"\n    }\n    with open(f\"{TOKENIZER_DIR}/tokenizer_config.json\", \"w\") as f:\n        json.dump(tokenizer_config, f, indent=2, ensure_ascii=False)\n    \n    # åˆ›å»º special_tokens_map.json\n    special_tokens = {\n        \"bos_token\": \"<s>\",\n        \"eos_token\": \"</s>\",\n        \"unk_token\": \"<unk>\",\n        \"pad_token\": \"<pad>\"\n    }\n    with open(f\"{TOKENIZER_DIR}/special_tokens_map.json\", \"w\") as f:\n        json.dump(special_tokens, f, indent=2, ensure_ascii=False)\n    \n    # ä½¿ç”¨ LlamaTokenizerFast åŠ è½½ SP æ¨¡å‹\n    tokenizer = LlamaTokenizerFast(\n        vocab_file=f\"{MODEL_PREFIX}.model\",\n        bos_token=\"<s>\",\n        eos_token=\"</s>\",\n        unk_token=\"<unk>\",\n        pad_token=\"<pad>\",\n        add_bos_token=False,\n        add_eos_token=True,\n    )\n    \n    # ä¿å­˜ä¸ºæ ‡å‡† HuggingFace æ ¼å¼\n    tokenizer.save_pretrained(TOKENIZER_DIR)\n    print(f\"âœ… åˆ†è¯å™¨è½¬æ¢å®Œæˆ!\")\n    print(f\"   ç›®å½•: {TOKENIZER_DIR}\")\n    print(f\"   è¯è¡¨å¤§å°: {len(tokenizer)}\")\n    \n    # === ä¸Šä¼ åˆ†è¯å™¨åˆ° HuggingFace Hub ===\n    TOKENIZER_REPO = f\"{HF_USERNAME}/chinese-sp-32k\"\n    try:\n        tokenizer.push_to_hub(TOKENIZER_REPO)\n        print(f\"\\nğŸš€ åˆ†è¯å™¨å·²ä¸Šä¼ è‡³: https://huggingface.co/{TOKENIZER_REPO}\")\n        print(f\"   ä½¿ç”¨æ–¹å¼: AutoTokenizer.from_pretrained('{TOKENIZER_REPO}')\")\n    except Exception as e:\n        print(f\"âš ï¸ ä¸Šä¼ å¤±è´¥: {e}\")\n        print(\"   å¯ç¨åæ‰‹åŠ¨ä¸Šä¼ : tokenizer.push_to_hub('ä½ çš„ä»“åº“å')\")\n    \n    # æµ‹è¯•åˆ†è¯æ•ˆæœ\n    test_text = \"äººå·¥æ™ºèƒ½æ˜¯æœªæ¥ç§‘æŠ€å‘å±•çš„é‡è¦æ–¹å‘ã€‚\"\n    tokens = tokenizer.tokenize(test_text)\n    ids = tokenizer.encode(test_text)\n    print(f\"\\næµ‹è¯•åˆ†è¯:\")\n    print(f\"   åŸæ–‡: {test_text}\")\n    print(f\"   Tokens: {tokens}\")\n    print(f\"   IDs: {ids}\")\n    print(f\"   è§£ç : {tokenizer.decode(ids)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-03T05:30:15.959825Z","iopub.execute_input":"2026-02-03T05:30:15.960509Z","iopub.status.idle":"2026-02-03T05:30:16.080578Z","shell.execute_reply.started":"2026-02-03T05:30:15.960478Z","shell.execute_reply":"2026-02-03T05:30:16.079891Z"}},"outputs":[{"name":"stdout","text":"==================================================\nâœ… æ£€æµ‹åˆ°å·²è½¬æ¢çš„ HuggingFace åˆ†è¯å™¨ï¼Œè·³è¿‡è½¬æ¢\n   ç›®å½•: /kaggle/working/tokenizer\n   è¯è¡¨å¤§å°: 32000\n   æµ‹è¯•: äººå·¥æ™ºèƒ½æ˜¯æœªæ¥ç§‘æŠ€å‘å±•çš„é‡è¦æ–¹å‘ã€‚... â†’ ['äººå·¥æ™ºèƒ½', 'æ˜¯', 'æœªæ¥', 'ç§‘æŠ€', 'å‘å±•']...\n==================================================\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"**CAUTION**\n\nå…³é”®æ£€æŸ¥ç‚¹: ç¡®ä¿ tokenizer.decode(tokenizer.encode(text)) == text å¦‚æœè§£ç ç»“æœä¸åŸæ–‡ä¸ä¸€è‡´ï¼Œè¯´æ˜åˆ†è¯å™¨é…ç½®æœ‰é—®é¢˜ã€‚","metadata":{}},{"cell_type":"markdown","source":"# ğŸ§  ç¬¬ä¸‰é˜¶æ®µï¼šæ¨¡å‹åˆå§‹åŒ–ä¸æ•°æ®ç®¡é“","metadata":{}},{"cell_type":"markdown","source":"**3.1 æ¨¡å‹æ¶æ„é…ç½®**","metadata":{}},{"cell_type":"code","source":"# === Cell 6: GPT-2 æ¨¡å‹é…ç½®ä¸åˆå§‹åŒ– ===\nfrom transformers import GPT2Config, GPT2LMHeadModel\n# é‡æ–°åŠ è½½åˆ†è¯å™¨ (ç¡®ä¿ä½¿ç”¨æœ€æ–°ä¿å­˜çš„ç‰ˆæœ¬)\nfrom transformers import AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained(TOKENIZER_DIR)\n# === æ¨¡å‹é…ç½®ï¼ˆä¼˜åŒ–ç‰ˆï¼‰===\nconfig = GPT2Config(\n    vocab_size=len(tokenizer),\n    \n    # === æ¶æ„ï¼ˆä¼˜åŒ–åï¼‰===\n    n_positions=1024,                   # å¢å¤§ contextï¼ˆæ˜¾å­˜ä¼˜åŒ–åæ”¯æŒï¼‰\n    n_ctx=1024,\n    n_embd=768,\n    n_layer=6,\n    n_head=12,\n    n_inner=3072,\n    activation_function=\"gelu_new\",\n    \n    # === æ­£åˆ™åŒ–ï¼ˆé¢„è®­ç»ƒé˜¶æ®µå…³é—­ dropoutï¼‰===\n    resid_pdrop=0.0,\n    embd_pdrop=0.0,\n    attn_pdrop=0.0,\n    \n    # === ç‰¹æ®Š Token ID ===\n    bos_token_id=tokenizer.bos_token_id,\n    eos_token_id=tokenizer.eos_token_id,\n    pad_token_id=tokenizer.pad_token_id,\n)\n# === ä¼˜åŒ– 0: SDPA Attention ===\ntry:\n    config._attn_implementation = \"sdpa\"\n    print(\"âœ… å·²è®¾ç½® SDPA attentionï¼ˆMemory-Efficient åç«¯ï¼‰\")\nexcept:\n    pass\n# åˆå§‹åŒ–æ¨¡å‹ (éšæœºæƒé‡)\nmodel = GPT2LMHeadModel(config)\nprint(f\"âœ… å‚æ•°é‡: {sum(p.numel() for p in model.parameters()) / 1e6:.1f}M\")\n# === ä¼˜åŒ– 1: Liger Kernel LayerNormï¼ˆ+30% é€Ÿåº¦ï¼‰===\ntry:\n    from liger_kernel.transformers import LigerLayerNorm\n    import torch.nn as nn\n    \n    def patch_layernorm(model):\n        patched_count = 0\n        for name, module in list(model.named_modules()):\n            if isinstance(module, nn.LayerNorm):\n                parent_name = '.'.join(name.split('.')[:-1])\n                child_name = name.split('.')[-1]\n                parent = model.get_submodule(parent_name) if parent_name else model\n                liger_ln = LigerLayerNorm(module.normalized_shape, eps=module.eps)\n                liger_ln.weight = module.weight\n                if module.bias is not None:\n                    liger_ln.bias = module.bias\n                setattr(parent, child_name, liger_ln)\n                patched_count += 1\n        return model, patched_count\n    \n    model, count = patch_layernorm(model)\n    print(f\"âœ… å·²æ›¿æ¢ {count} ä¸ª LayerNorm ä¸º Liger ç‰ˆæœ¬\")\nexcept ImportError:\n    print(\"âš ï¸ liger-kernel æœªå®‰è£…ï¼Œè·³è¿‡ LayerNorm ä¼˜åŒ–\")\n# ä¿å­˜ lm_head.weightï¼ˆä¾› FusedLinearCrossEntropy ä½¿ç”¨ï¼‰\nLM_HEAD_WEIGHT = model.lm_head.weight\n\n# === ä¼˜åŒ– 2: torch.compile ===\n# æ³¨æ„ï¼štorch.compile å’Œ DataParallel ä¸å…¼å®¹ï¼Œé€‰æ‹© DataParallelï¼ˆä½¿ç”¨åŒ GPUï¼‰\n# å¦‚æœåªæœ‰å• GPUï¼Œå¯ä»¥å¯ç”¨ torch.compile\nUSE_COMPILE = False  # DataParallel æ¨¡å¼ä¸‹å¿…é¡»ç¦ç”¨\nif USE_COMPILE and torch.cuda.device_count() == 1:\n    try:\n        model = torch.compile(model)\n        print(\"âœ… å·²å¯ç”¨ torch.compile\")\n    except Exception as e:\n        print(f\"âš ï¸ torch.compile ä¸å¯ç”¨: {e}\")\n\n# === ä¼˜åŒ– 3: Gradient Checkpointingï¼ˆåœ¨ DataParallel ä¹‹å‰å¯ç”¨ï¼‰===\n# å¿…é¡»åœ¨åŒ…è£… DataParallel ä¹‹å‰å¯ç”¨ï¼Œå¦åˆ™ Trainer ä¼šæŠ¥é”™\nmodel.gradient_checkpointing_enable()\nprint(\"âœ… å·²å¯ç”¨ Gradient Checkpointing\")\n\n# å¼ºåˆ¶ä½¿ç”¨ DataParallelï¼ˆåŒ GPUï¼‰\nif torch.cuda.device_count() > 1:\n    print(f\"ğŸ® å¯ç”¨ DataParallelï¼Œä½¿ç”¨ {torch.cuda.device_count()} ä¸ª GPU\")\n    model = torch.nn.DataParallel(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-03T05:30:25.727401Z","iopub.execute_input":"2026-02-03T05:30:25.728045Z","iopub.status.idle":"2026-02-03T05:30:43.015888Z","shell.execute_reply.started":"2026-02-03T05:30:25.728016Z","shell.execute_reply":"2026-02-03T05:30:43.015273Z"}},"outputs":[{"name":"stderr","text":"2026-02-03 05:30:28.112087: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1770096628.297556      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1770096628.347656      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1770096628.774592      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770096628.774619      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770096628.774622      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770096628.774624      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"name":"stdout","text":"âœ… å·²è®¾ç½® SDPA attentionï¼ˆMemory-Efficient åç«¯ï¼‰\nâœ… å‚æ•°é‡: 67.9M\nâœ… å·²æ›¿æ¢ 13 ä¸ª LayerNorm ä¸º Liger ç‰ˆæœ¬\nâœ… å·²å¯ç”¨ Gradient Checkpointing\nğŸ® å¯ç”¨ DataParallelï¼Œä½¿ç”¨ 2 ä¸ª GPU\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"**TIP**\n\ntorch.compile ä¼˜åŒ–ï¼š\n\nPyTorch 2.0+ çš„è®¡ç®—å›¾ç¼–è¯‘åŠŸèƒ½\n\nè‡ªåŠ¨èåˆç®—å­ï¼Œå‡å°‘ kernel å¯åŠ¨å¼€é”€\n\né¢„è®¡è®­ç»ƒé€Ÿåº¦æå‡ 50-100%\n\né¦–æ¬¡è¿è¡Œæœ‰ 1-2 åˆ†é’Ÿç¼–è¯‘å¼€é”€","metadata":{}},{"cell_type":"markdown","source":"**3.2 æ•°æ® Tokenization ä¸ Packing**","metadata":{}},{"cell_type":"code","source":"# === Cell 7: æ•°æ®é¢„å¤„ç†ä¸ Packingï¼ˆå¸¦ç¼“å­˜æ£€æµ‹ï¼‰===\nfrom datasets import Dataset, load_from_disk\nimport numpy as np\nimport multiprocessing\nimport time\nfrom itertools import chain\n\nNUM_PROC = multiprocessing.cpu_count()\nBLOCK_SIZE = 1024\nLM_DATASET_PATH = \"/kaggle/working/lm_dataset\"\n\n# === ç¼“å­˜æ£€æµ‹ï¼šå¦‚æœå¤„ç†åçš„æ•°æ®é›†å·²å­˜åœ¨åˆ™è·³è¿‡ ===\nif os.path.exists(LM_DATASET_PATH):\n    print(\"=\" * 50)\n    print(\"âœ… æ£€æµ‹åˆ°å·²å¤„ç†çš„æ•°æ®é›†ï¼Œä»ç¼“å­˜åŠ è½½\")\n    print(f\"   è·¯å¾„: {LM_DATASET_PATH}\")\n    lm_dataset = load_from_disk(LM_DATASET_PATH)\n    print(f\"   æ ·æœ¬æ•°: {len(lm_dataset)} ä¸ª {BLOCK_SIZE}-token å—\")\n    print(f\"   æ€» Token: {len(lm_dataset) * BLOCK_SIZE / 1e9:.2f}B\")\n    # éªŒè¯æ•°æ®\n    sample = lm_dataset[0]\n    print(f\"   è§£ç : {tokenizer.decode(sample['input_ids'][:50])}...\")\n    print(\"=\" * 50)\nelse:\n    print(f\"ğŸ–¥ï¸ ä½¿ç”¨ {NUM_PROC} ä¸ª CPU æ ¸å¿ƒå¹¶è¡Œå¤„ç†\")\n    \n    # === æ­¥éª¤ 1: Tokenize æ‰€æœ‰æ–‡æœ¬ ===\n    print(\"=\" * 50)\n    print(\"ğŸ”„ æ­£åœ¨ Tokenize...\")\n    tokenize_start = time.time()\n    \n    text_column = \"text\" if \"text\" in dataset.column_names else \"completion\"\n    print(f\"   å­—æ®µ: {text_column}\")\n    print(f\"   æ ·æœ¬æ•°: {len(dataset)}\")\n    \n    def tokenize_function(examples):\n        return tokenizer(\n            examples[text_column],\n            add_special_tokens=True,\n            truncation=False,\n            return_attention_mask=False,\n        )\n    \n    tokenized_dataset = dataset.map(\n        tokenize_function,\n        batched=True,\n        batch_size=5000,\n        remove_columns=dataset.column_names,\n        num_proc=NUM_PROC,\n        desc=\"Tokenizing\",\n    )\n    tokenize_time = time.time() - tokenize_start\n    print(f\"âœ… Tokenization å®Œæˆ: {len(tokenized_dataset)} æ ·æœ¬, è€—æ—¶ {tokenize_time:.1f}s\")\n    \n    # === æ­¥éª¤ 2: Packing ===\n    print(\"=\" * 50)\n    print(\"ğŸ“¦ æ­£åœ¨ Packing...\")\n    pack_start = time.time()\n    \n    def group_texts(examples):\n        concatenated = {k: list(chain.from_iterable(examples[k])) for k in examples.keys()}\n        total_length = len(concatenated[\"input_ids\"])\n        \n        if total_length >= BLOCK_SIZE:\n            total_length = (total_length // BLOCK_SIZE) * BLOCK_SIZE\n        \n        result = {\n            k: [t[i : i + BLOCK_SIZE] for i in range(0, total_length, BLOCK_SIZE)]\n            for k, t in concatenated.items()\n        }\n        result[\"labels\"] = result[\"input_ids\"].copy()\n        return result\n    \n    lm_dataset = tokenized_dataset.map(\n        group_texts,\n        batched=True,\n        batch_size=5000,\n        num_proc=NUM_PROC,\n        desc=\"Packing\",\n    )\n    pack_time = time.time() - pack_start\n    \n    # ä¿å­˜åˆ°ç£ç›˜ä½œä¸ºç¼“å­˜\n    lm_dataset.save_to_disk(LM_DATASET_PATH)\n    \n    total_time = tokenize_time + pack_time\n    print(\"=\" * 50)\n    print(f\"âœ… æ•°æ®å¤„ç†å®Œæˆ!\")\n    print(f\"   Tokenize: {tokenize_time:.1f}s\")\n    print(f\"   Packing: {pack_time:.1f}s\")\n    print(f\"   æ€»è€—æ—¶: {total_time:.1f}s\")\n    print(f\"   æ ·æœ¬æ•°: {len(lm_dataset)} ä¸ª {BLOCK_SIZE}-token å—\")\n    print(f\"   æ€» Token: {len(lm_dataset) * BLOCK_SIZE / 1e9:.2f}B\")\n    print(f\"   å·²ç¼“å­˜è‡³: {LM_DATASET_PATH}\")\n    \n    # éªŒè¯æ•°æ®\n    sample = lm_dataset[0]\n    print(f\"\\nğŸ“Š æ•°æ®æ ·æœ¬:\")\n    print(f\"   è§£ç : {tokenizer.decode(sample['input_ids'][:50])}...\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-03T05:30:48.591835Z","iopub.execute_input":"2026-02-03T05:30:48.592903Z","iopub.status.idle":"2026-02-03T05:41:40.060267Z","shell.execute_reply.started":"2026-02-03T05:30:48.592868Z","shell.execute_reply":"2026-02-03T05:41:40.059563Z"}},"outputs":[{"name":"stdout","text":"ğŸ–¥ï¸ ä½¿ç”¨ 4 ä¸ª CPU æ ¸å¿ƒå¹¶è¡Œå¤„ç†\n==================================================\nğŸ”„ æ­£åœ¨ Tokenize...\n   å­—æ®µ: text\n   æ ·æœ¬æ•°: 1260765\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Tokenizing (num_proc=4):   0%|          | 0/1260765 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b31c8d267e744128831f6431b96ce2d"}},"metadata":{}},{"name":"stdout","text":"âœ… Tokenization å®Œæˆ: 1260765 æ ·æœ¬, è€—æ—¶ 430.9s\n==================================================\nğŸ“¦ æ­£åœ¨ Packing...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Packing (num_proc=4):   0%|          | 0/1260765 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed6fa23eee914b1b972a951a2c5ca666"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Saving the dataset (0/15 shards):   0%|          | 0/579166 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"621e4eaaa9b34c8297fffc5e7a092cb8"}},"metadata":{}},{"name":"stdout","text":"==================================================\nâœ… æ•°æ®å¤„ç†å®Œæˆ!\n   Tokenize: 430.9s\n   Packing: 209.4s\n   æ€»è€—æ—¶: 640.3s\n   æ ·æœ¬æ•°: 579166 ä¸ª 1024-token å—\n   æ€» Token: 0.59B\n   å·²ç¼“å­˜è‡³: /kaggle/working/lm_dataset\n\nğŸ“Š æ•°æ®æ ·æœ¬:\n   è§£ç : å¦‚ä½•çœ‹å¾…è…¾è®¯å°† <pad>team ç½‘ç«™æ¶æ„åˆ—ä¸ºå±é™©ç½‘ç«™<pad>ä¸æ˜¯è¿™ä¸ªç½‘ç«™å¯¹ä½ æœ‰å±é™©<pad>æ˜¯ä½ ä¸Šè¿™ä¸ªç½‘ç«™å¯¹è…¾è®¯æœ‰å±é™©<pad>æ‰€ä»¥å®ƒè¯´çš„æ²¡é”™</s>ä½ è®¤ä¸ºè‚–æ–¯å¡”ç§‘ç»´å¥‡æœ€ä¼Ÿå¤§çš„ä½œå“æ˜¯ä»€ä¹ˆ<pad>ç¬¬åå››äº¤å“æ›²æ˜¯è‚–æ–¯å¡”ç»´å¥‡æ™šå¹´...\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"**WARNING**\n\nPacking æ³¨æ„äº‹é¡¹:\n\nPacking ä¼šå¯¼è‡´ä¸åŒæ–‡ç« çš„ token æ··åœ¨åŒä¸€ä¸ªåºåˆ—ä¸­\næ¨¡å‹ä¼šå­¦åˆ°è·¨æ–‡ç« çš„é”™è¯¯å…³è”\nç¼“è§£æ–¹æ³•: åœ¨æ¯ç¯‡æ–‡ç« æœ«å°¾æ·»åŠ  <eos> token (ä¸Šé¢å·²é…ç½® add_eos_token=True)","metadata":{}},{"cell_type":"markdown","source":"# ğŸš‚ ç¬¬å››é˜¶æ®µï¼šåˆ†å¸ƒå¼è®­ç»ƒé…ç½®","metadata":{}},{"cell_type":"markdown","source":"**4.1 è®­ç»ƒå‚æ•°ä¼˜åŒ–**","metadata":{}},{"cell_type":"code","source":"# === Cell 8: è®­ç»ƒå‚æ•°é…ç½® ===\nfrom transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling\n# === æ¨¡å‹å‘½å ===\nMODEL_NAME = \"gpt2-chinese-mini\"\nREPO_ID = f\"{HF_USERNAME}/{MODEL_NAME}\"\n# === è®­ç»ƒå‚æ•°ï¼ˆæ˜¾å­˜ä¼˜åŒ–ç‰ˆï¼‰===\nNUM_EPOCHS = 2\nBATCH_SIZE_PER_GPU = 16              # DataParallel æ¨¡å¼ä¸‹é™ä½ batch size\nGRADIENT_ACCUMULATION = 2\nNUM_GPUS = 2\nBLOCK_SIZE = 1024\n# æœ‰æ•ˆ batch size = 24 * 2 * 2 = 96 samples\n# æ¯ä¸ª sample 1024 tokens = ~98K tokens per update\neffective_batch_size = BATCH_SIZE_PER_GPU * GRADIENT_ACCUMULATION * NUM_GPUS\ntokens_per_update = effective_batch_size * BLOCK_SIZE\nsteps_per_epoch = len(lm_dataset) // effective_batch_size\ntotal_steps = steps_per_epoch * NUM_EPOCHS\nprint(f\"ğŸ“Š è®­ç»ƒè§„æ¨¡:\")\nprint(f\"   æ¯ GPU batch: {BATCH_SIZE_PER_GPU}\")\nprint(f\"   æ¢¯åº¦ç´¯ç§¯: {GRADIENT_ACCUMULATION}\")\nprint(f\"   æœ‰æ•ˆ batch: {effective_batch_size}\")\nprint(f\"   æ¯æ­¥ tokens: {tokens_per_update / 1e3:.1f}K\")\nprint(f\"   æ€»æ­¥æ•°: {total_steps}\")\n# === è®­ç»ƒå‚æ•° ===\ntraining_args = TrainingArguments(\n    output_dir=f\"/kaggle/working/{MODEL_NAME}\",\n    overwrite_output_dir=True,\n    \n    # === è®­ç»ƒè§„æ¨¡ ===\n    num_train_epochs=NUM_EPOCHS,\n    per_device_train_batch_size=BATCH_SIZE_PER_GPU,\n    gradient_accumulation_steps=GRADIENT_ACCUMULATION,\n    \n    # === å­¦ä¹ ç‡è°ƒåº¦ï¼ˆé’ˆå¯¹å¤§ batch ä¼˜åŒ–ï¼‰===\n    learning_rate=3e-4,                  # å¤§ batch æ—¶é™ä½ LR\n    warmup_steps=2000,                   # çº¦ 5% æ€»æ­¥æ•°\n    lr_scheduler_type=\"cosine\",\n    \n    # === ä¼˜åŒ–å™¨ï¼ˆ8-bit ä¼˜åŒ–ï¼Œæ˜¾å­˜å‡å°‘ 75%ï¼‰===\n    optim=\"adamw_bnb_8bit\",\n    weight_decay=0.1,\n    adam_beta1=0.9,\n    adam_beta2=0.95,\n    max_grad_norm=1.0,\n    \n    # === ç²¾åº¦ ===\n    fp16=True,\n    bf16=False,                          # T4 ä¸æ”¯æŒ\n    gradient_checkpointing=False,        # å·²åœ¨ Cell 6 æ‰‹åŠ¨å¯ç”¨ï¼ˆDataParallel å‰ï¼‰\n    \n    # === æ•°æ®åŠ è½½ä¼˜åŒ– ===\n    dataloader_num_workers=4,\n    dataloader_pin_memory=True,\n    dataloader_prefetch_factor=4,\n    dataloader_persistent_workers=True,\n    \n    # === Checkpoint ===\n    eval_strategy=\"steps\",\n    eval_steps=500,\n    save_strategy=\"steps\",\n    save_steps=500,\n    save_total_limit=3,\n    load_best_model_at_end=False,\n    prediction_loss_only=True,    # å¼ºåˆ¶è®¡ç®— eval loss\n    \n    # === æ—¥å¿—ä¸ Hub ===\n    logging_steps=1,               # å‰å‡ æ­¥æ¯æ­¥æ‰“å°ï¼Œç¡®è®¤æ— è¯¯åæ”¹ä¸º 100\n    logging_first_step=True,\n    report_to=\"none\",\n    push_to_hub=True,\n    hub_model_id=REPO_ID,\n    hub_strategy=\"checkpoint\",\n    \n    # === åˆ†å¸ƒå¼ ===\n    ddp_find_unused_parameters=False,\n    remove_unused_columns=False,  # torch.compile å…¼å®¹\n    seed=42,\n)\nprint(f\"\\nâœ… è®­ç»ƒé…ç½®å®Œæˆ\")\nprint(f\"   Warmup æ­¥æ•°: {training_args.warmup_steps}\")\nprint(f\"   LR è°ƒåº¦: {training_args.lr_scheduler_type}\")\nprint(f\"   ä¼˜åŒ–å™¨: {training_args.optim}\")\nprint(f\"   ä¿å­˜é—´éš”: {training_args.save_steps} æ­¥\") ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-03T05:41:47.626282Z","iopub.execute_input":"2026-02-03T05:41:47.626625Z","iopub.status.idle":"2026-02-03T05:41:49.567559Z","shell.execute_reply.started":"2026-02-03T05:41:47.626592Z","shell.execute_reply":"2026-02-03T05:41:49.566825Z"}},"outputs":[{"name":"stdout","text":"ğŸ“Š è®­ç»ƒè§„æ¨¡:\n   æ¯ GPU batch: 16\n   æ¢¯åº¦ç´¯ç§¯: 2\n   æœ‰æ•ˆ batch: 64\n   æ¯æ­¥ tokens: 65.5K\n   æ€»æ­¥æ•°: 18098\n\nâœ… è®­ç»ƒé…ç½®å®Œæˆ\n   Warmup æ­¥æ•°: 2000\n   LR è°ƒåº¦: SchedulerType.COSINE\n   ä¼˜åŒ–å™¨: OptimizerNames.ADAMW_BNB\n   ä¿å­˜é—´éš”: 500 æ­¥\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"**TIP**\nä¼˜åŒ–æ€»ç»“ï¼š\n\næ˜¾å­˜ä¼˜åŒ–å batch_size 16â†’24ï¼Œcontext 512â†’1024\n\nå¤§ batch éœ€é™ä½ learning_rate 6e-4â†’3e-4\n\nadamw_bnb_8bit + Liger Kernel å…±èŠ‚çœ 80%+ æ˜¾å­˜","metadata":{}},{"cell_type":"markdown","source":"**IMPORTANT**\nChinchilla åˆ†æï¼š\n\nå½“å‰ï¼š625M tokens / 67.5M params â‰ˆ 9 tokens/param\n\nç†æƒ³ï¼š20-25 tokens/paramï¼ˆéœ€ 1.3-1.6B tokensï¼‰\n\nç»“è®ºï¼šæ•°æ®ç•¥å°‘ï¼Œ2 epochs å……åˆ†è®­ç»ƒ","metadata":{}},{"cell_type":"markdown","source":"**4.2 Data Collator**","metadata":{}},{"cell_type":"code","source":"# === Cell 9: Data Collator é…ç½® ===\n# è¯­è¨€æ¨¡å‹ä¸“ç”¨ Data Collator\ndata_collator = DataCollatorForLanguageModeling(\n    tokenizer=tokenizer,\n    mlm=False,  # å› æœè¯­è¨€æ¨¡å‹ (é Masked LM)\n)\n# æµ‹è¯• collator\ntest_batch = [lm_dataset[i] for i in range(4)]\ncollated = data_collator(test_batch)\nprint(\"ğŸ“¦ Data Collator æµ‹è¯•:\")\nprint(f\"   input_ids shape: {collated['input_ids'].shape}\")\nprint(f\"   labels shape: {collated['labels'].shape}\") ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-03T05:41:54.435627Z","iopub.execute_input":"2026-02-03T05:41:54.436445Z","iopub.status.idle":"2026-02-03T05:42:01.423257Z","shell.execute_reply.started":"2026-02-03T05:41:54.436416Z","shell.execute_reply":"2026-02-03T05:42:01.422450Z"}},"outputs":[{"name":"stdout","text":"ğŸ“¦ Data Collator æµ‹è¯•:\n   input_ids shape: torch.Size([4, 1024])\n   labels shape: torch.Size([4, 1024])\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"**4.3 åˆ›å»º Trainer**","metadata":{}},{"cell_type":"code","source":"# === Cell 10: è‡ªå®šä¹‰ Trainer + ç”Ÿæˆå›è°ƒ ===\nfrom transformers import Trainer, TrainerCallback\n# ç¡®ä¿ LM_HEAD_WEIGHT å­˜åœ¨ï¼ˆå¦‚æœä¹‹å‰çš„ Cell æ²¡æœ‰å®šä¹‰ï¼‰\ntry:\n    LM_HEAD_WEIGHT\nexcept NameError:\n    # å¤„ç† DataParallel åŒ…è£…\n    base_model = model.module if hasattr(model, 'module') else model\n    # å¤„ç† torch.compile åŒ…è£…\n    base_model = base_model._orig_mod if hasattr(base_model, '_orig_mod') else base_model\n    LM_HEAD_WEIGHT = base_model.lm_head.weight\n    print(\"âœ… å·²è·å– LM_HEAD_WEIGHT\")\n# === ç”Ÿæˆå›è°ƒï¼šæ¯æ¬¡è¯„ä¼°æ—¶æµ‹è¯• prompt ===\nclass GenerationCallback(TrainerCallback):\n    def __init__(self, tokenizer, prompts=None):\n        self.tokenizer = tokenizer\n        self.prompts = prompts or [\"ä¸­å›½çš„å†å²\", \"äººå·¥æ™ºèƒ½æ˜¯\", \"çŸ¥ä¹ä¸Šæœ‰äººé—®\"]\n    \n    def on_evaluate(self, args, state, control, model, **kwargs):\n        print(\"\\n\" + \"=\" * 50)\n        print(f\"ğŸ“ Step {state.global_step} - ç”Ÿæˆæ ·æœ¬:\")\n        print(\"=\" * 50)\n        \n        # å¤„ç† DataParallel å’Œ torch.compile åŒ…è£…\n        eval_model = model\n        if hasattr(model, 'module'):  # DataParallel\n            eval_model = model.module\n        if hasattr(eval_model, '_orig_mod'):  # torch.compile\n            eval_model = eval_model._orig_mod\n        \n        eval_model.eval()\n        device = next(eval_model.parameters()).device\n        for prompt in self.prompts:\n            try:\n                inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(device)\n                with torch.no_grad():\n                    outputs = eval_model.generate(\n                        **inputs, max_new_tokens=50,\n                        do_sample=True, temperature=0.8, top_k=50,\n                        pad_token_id=self.tokenizer.pad_token_id,\n                    )\n                generated = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n                print(f\"  [{prompt}] â†’ {generated}\")\n            except Exception as e:\n                print(f\"  [{prompt}] â†’ ç”Ÿæˆå¤±è´¥: {e}\")\n        print(\"=\" * 50 + \"\\n\")\n        eval_model.train()\n# === æ—¥å¿—å›è°ƒï¼šå‰ 10 æ­¥æ¯æ­¥æ‰“å°ï¼Œä¹‹åæ¯ 100 æ­¥ ===\nclass LoggingCallback(TrainerCallback):\n    def on_log(self, args, state, control, logs=None, **kwargs):\n        if logs:\n            loss = logs.get(\"loss\", logs.get(\"eval_loss\", None))\n            if loss is not None:\n                step = state.global_step\n                # å‰ 10 æ­¥æ¯æ­¥æ‰“å°ï¼Œä¹‹åæ¯ 100 æ­¥æ‰“å°\n                if step <= 10 or step % 100 == 0:\n                    lr = logs.get(\"learning_rate\", 0)\n                    print(f\"ğŸ“Š Step {step}: loss={loss:.4f}, lr={lr:.2e}\")\n# === LigerTrainer: ä½¿ç”¨ FusedLinearCrossEntropy ===\nUSE_FUSED_CE = False  # è®¾ç½®ä¸º False å¯ç¦ç”¨\ntry:\n    from liger_kernel.transformers import LigerFusedLinearCrossEntropyLoss\n    \n    class LigerTrainer(Trainer):\n        \"\"\"ä½¿ç”¨ FusedLinearCrossEntropyï¼Œæ˜¾å­˜ -60~80%\"\"\"\n        def __init__(self, *args, lm_head_weight=None, **kwargs):\n            super().__init__(*args, **kwargs)\n            self.fused_loss_fn = LigerFusedLinearCrossEntropyLoss()\n            self.lm_head_weight = lm_head_weight\n            print(\"âœ… LigerTrainer: å·²å¯ç”¨ FusedLinearCrossEntropy\")\n        \n        def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n            labels = inputs.pop(\"labels\")\n            base_model = getattr(model, '_orig_mod', model)\n            transformer = getattr(base_model, 'transformer', None)\n            outputs = transformer(\n                input_ids=inputs[\"input_ids\"],\n                attention_mask=inputs.get(\"attention_mask\"),\n            )\n            hidden_states = outputs.last_hidden_state\n            shift_hidden = hidden_states[..., :-1, :].contiguous().view(-1, hidden_states.size(-1))\n            shift_labels = labels[..., 1:].contiguous().view(-1)\n            loss = self.fused_loss_fn(self.lm_head_weight, shift_hidden, shift_labels)\n            if return_outputs:\n                from transformers.modeling_outputs import CausalLMOutputWithPast\n                return loss, CausalLMOutputWithPast(loss=loss)\n            return loss\n    \n    if USE_FUSED_CE:\n        TrainerClass = LigerTrainer\n        trainer_kwargs = {\"lm_head_weight\": LM_HEAD_WEIGHT}\n        print(\"âœ… å°†ä½¿ç”¨ LigerTrainer + FusedLinearCrossEntropy\")\n    else:\n        TrainerClass = Trainer\n        trainer_kwargs = {}\nexcept ImportError:\n    print(\"âš ï¸ liger-kernel æœªå®‰è£…ï¼Œä½¿ç”¨æ ‡å‡† Trainer\")\n    TrainerClass = Trainer\n    trainer_kwargs = {}\n# === åˆ›å»º Trainer ===\ngeneration_callback = GenerationCallback(\n    tokenizer=tokenizer,\n    prompts=[\"ä¸­å›½çš„å†å²\", \"äººå·¥æ™ºèƒ½æ˜¯\", \"çŸ¥ä¹ä¸Šæœ‰äººé—®\", \"ç§‘å­¦æŠ€æœ¯çš„å‘å±•\"]\n)\nlogging_callback = LoggingCallback()\ntrainer = TrainerClass(\n    model=model,\n    args=training_args,\n    train_dataset=lm_dataset,\n    eval_dataset=lm_dataset.select(range(min(1000, len(lm_dataset)))),\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    callbacks=[generation_callback, logging_callback],  # ä¸¤ä¸ªå›è°ƒ\n    **trainer_kwargs,\n)\nprint(\"ğŸ¯ Trainer åˆ›å»ºå®Œæˆ!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-03T05:42:07.268991Z","iopub.execute_input":"2026-02-03T05:42:07.269741Z","iopub.status.idle":"2026-02-03T05:42:07.388397Z","shell.execute_reply.started":"2026-02-03T05:42:07.269711Z","shell.execute_reply":"2026-02-03T05:42:07.387691Z"}},"outputs":[{"name":"stdout","text":"ğŸ¯ Trainer åˆ›å»ºå®Œæˆ!\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_55/267342749.py:106: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = TrainerClass(\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"# ğŸš€ ç¬¬äº”é˜¶æ®µï¼šè®­ç»ƒæ‰§è¡Œ","metadata":{}},{"cell_type":"markdown","source":"**5.1 å¯åŠ¨è®­ç»ƒ**","metadata":{}},{"cell_type":"code","source":"# === Cell 11: å¤š GPU è®­ç»ƒï¼ˆDataParallel æ¨¡å¼ï¼‰===\n# æ³¨æ„ï¼šKaggle ç¯å¢ƒä¸æ”¯æŒ DDPï¼ŒTrainer ä¼šè‡ªåŠ¨ä½¿ç”¨ DataParallel\nimport time\nimport gc\nimport torch\n# æ¸…ç† GPU ç¼“å­˜\ngc.collect()\ntorch.cuda.empty_cache()\nprint(\"=\" * 60)\nprint(\"ğŸš€ å¼€å§‹å¤š GPU é¢„è®­ç»ƒ\")\nprint(\"=\" * 60)\nprint(f\"â° å¼€å§‹æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\")\nprint(f\"ğŸ–¥ï¸ GPU æ˜¾å­˜: {torch.cuda.memory_allocated() / 1024**3:.2f} GB å·²ç”¨\")\nprint(f\"ğŸ® GPU æ•°é‡: {torch.cuda.device_count()}\")\nprint(f\"ğŸ“ æ¨¡å‹å°†ä¸Šä¼ è‡³: https://huggingface.co/{REPO_ID}\")\nprint()\nprint(\"ğŸ“ˆ Loss å‚è€ƒ:\")\nprint(\"   åˆå§‹ (éšæœºæƒé‡): ~10.0 - 11.0\")\nprint(\"   500 æ­¥å: ~6.0 - 7.0\")\nprint(\"   æ”¶æ•›ç›®æ ‡: < 4.0\")\nprint(\"=\" * 60)\n# === å…³é”®æ£€æŸ¥ï¼švocab_size ä¸€è‡´æ€§ ===\n# å¤„ç† DataParallel åŒ…è£…\nbase_model = model.module if hasattr(model, 'module') else model\nmodel_vocab = base_model.config.vocab_size\ntokenizer_vocab = len(tokenizer)\nprint(f\"\\nğŸ” vocab_size æ£€æŸ¥:\")\nprint(f\"   æ¨¡å‹: {model_vocab}\")\nprint(f\"   åˆ†è¯å™¨: {tokenizer_vocab}\")\nif model_vocab != tokenizer_vocab:\n    print(f\"âŒ é”™è¯¯: vocab_size ä¸åŒ¹é…! æ¨¡å‹={model_vocab}, åˆ†è¯å™¨={tokenizer_vocab}\")\n    print(\"   è¯·é‡æ–°è¿è¡Œ Cell 6 åˆ›å»ºæ¨¡å‹ï¼Œç¡®ä¿ä½¿ç”¨ vocab_size=len(tokenizer)\")\n    raise ValueError(f\"vocab_size mismatch: model={model_vocab}, tokenizer={tokenizer_vocab}\")\n# æ£€æŸ¥æ•´ä¸ªæ•°æ®é›†çš„ token ID èŒƒå›´ï¼ˆæŠ½æ ·æ£€æŸ¥ï¼‰\nprint(\"   æ£€æŸ¥æ•°æ®é›† token ID èŒƒå›´...\")\nmax_token_id = 0\nproblem_samples = []\nfor i in range(0, len(lm_dataset), max(1, len(lm_dataset) // 100)):  # æŠ½æ · 100 ä¸ª\n    sample_ids = lm_dataset[i][\"input_ids\"]\n    sample_max = max(sample_ids)\n    if sample_max > max_token_id:\n        max_token_id = sample_max\n    if sample_max >= model_vocab:\n        problem_samples.append((i, sample_max))\nprint(f\"   æ•°æ®é›†æœ€å¤§ token ID: {max_token_id}\")\nprint(f\"   æ¨¡å‹ vocab_size: {model_vocab}\")\nif problem_samples:\n    print(f\"âŒ å‘ç° {len(problem_samples)} ä¸ªæ ·æœ¬çš„ token ID è¶Šç•Œ!\")\n    for idx, max_id in problem_samples[:5]:\n        print(f\"   æ ·æœ¬ {idx}: max_token_id = {max_id} >= {model_vocab}\")\n    print(\"\\nğŸ’¡ è§£å†³æ–¹æ¡ˆ:\")\n    print(\"   1. åˆ é™¤ /kaggle/working/tokenizer ç›®å½•\")\n    print(\"   2. é‡æ–°è¿è¡Œ Cell 4 (è®­ç»ƒåˆ†è¯å™¨)\")\n    print(\"   3. é‡æ–°è¿è¡Œ Cell 5 (ä¿å­˜åˆ†è¯å™¨)\")\n    print(\"   4. é‡æ–°è¿è¡Œ Cell 6-10\")\n    raise ValueError(f\"Token IDs out of range!\")\nif max_token_id >= model_vocab:\n    print(f\"âŒ é”™è¯¯: token ID {max_token_id} >= vocab_size {model_vocab}\")\n    raise ValueError(f\"Token ID out of range: {max_token_id} >= {model_vocab}\")\nprint(\"âœ… vocab_size æ£€æŸ¥é€šè¿‡!\\n\")\n# === å¼€å§‹è®­ç»ƒ ===\ntry:\n    trainer.train()\n    print(\"\\nâœ… è®­ç»ƒå®Œæˆ!\")\n    \n    # ä¿å­˜æ¨¡å‹\n    trainer.save_model()\n    tokenizer.save_pretrained(f\"/kaggle/working/{MODEL_NAME}\")\n    \n    # ä¸Šä¼ åˆ° Hub\n    print(\"\\nğŸ“¤ æ­£åœ¨ä¸Šä¼ æœ€ç»ˆæ¨¡å‹åˆ° HuggingFace Hub...\")\n    from huggingface_hub import HfApi\n    api = HfApi()\n    api.upload_folder(\n        folder_path=f\"/kaggle/working/{MODEL_NAME}\",\n        repo_id=REPO_ID,\n        commit_message=\"Training complete\"\n    )\n    print(f\"\\nğŸ‰ æ¨¡å‹å·²å‘å¸ƒè‡³: https://huggingface.co/{REPO_ID}\")\n    \nexcept KeyboardInterrupt:\n    print(\"\\nâš ï¸ è®­ç»ƒè¢«ä¸­æ–­ï¼Œæ­£åœ¨ä¿å­˜å½“å‰çŠ¶æ€...\")\n    trainer.save_model()\n    print(\"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜ï¼Œä¸‹æ¬¡å¯ç”¨ resume_from_checkpoint=True ç»§ç»­\")\n    \nexcept Exception as e:\n    print(f\"\\nâŒ è®­ç»ƒå‡ºé”™: {e}\")\n    print(\"\\nğŸ’¡ æ’é”™æŒ‡å—:\")\n    print(\"   - OOM: å‡å°‘ BATCH_SIZE_PER_GPU\")\n    print(\"   - é€Ÿåº¦æ…¢: æ£€æŸ¥ gradient_checkpointing\")\n    print(\"   - Loss ä¸é™: æ£€æŸ¥æ•°æ®å’Œ learning_rate\")\n    raise","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T19:14:51.874875Z","iopub.execute_input":"2026-02-02T19:14:51.875548Z","execution_failed":"2026-02-03T05:00:05.018Z"}},"outputs":[{"name":"stdout","text":"============================================================\nğŸš€ å¼€å§‹å¤š GPU é¢„è®­ç»ƒ\n============================================================\nâ° å¼€å§‹æ—¶é—´: 2026-02-02 19:15:12\nğŸ–¥ï¸ GPU æ˜¾å­˜: 0.28 GB å·²ç”¨\nğŸ® GPU æ•°é‡: 2\nğŸ“ æ¨¡å‹å°†ä¸Šä¼ è‡³: https://huggingface.co/Wilsonwin/gpt2-chinese-mini\n\nğŸ“ˆ Loss å‚è€ƒ:\n   åˆå§‹ (éšæœºæƒé‡): ~10.0 - 11.0\n   500 æ­¥å: ~6.0 - 7.0\n   æ”¶æ•›ç›®æ ‡: < 4.0\n============================================================\n\nğŸ” vocab_size æ£€æŸ¥:\n   æ¨¡å‹: 32000\n   åˆ†è¯å™¨: 32000\n   æ£€æŸ¥æ•°æ®é›† token ID èŒƒå›´...\n   æ•°æ®é›†æœ€å¤§ token ID: 31991\n   æ¨¡å‹ vocab_size: 32000\nâœ… vocab_size æ£€æŸ¥é€šè¿‡!\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='10086' max='18100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [10086/18100 9:44:45 < 7:44:43, 0.29 it/s, Epoch 1.11/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>7.590900</td>\n      <td>No log</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>6.907700</td>\n      <td>No log</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>6.184900</td>\n      <td>No log</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>5.664300</td>\n      <td>No log</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>5.490800</td>\n      <td>No log</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>5.343200</td>\n      <td>No log</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>5.178100</td>\n      <td>No log</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>5.098000</td>\n      <td>No log</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>4.987400</td>\n      <td>No log</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>4.973800</td>\n      <td>No log</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>4.797200</td>\n      <td>No log</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>4.892100</td>\n      <td>No log</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>4.771000</td>\n      <td>No log</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>4.913300</td>\n      <td>No log</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>4.761600</td>\n      <td>No log</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>4.635200</td>\n      <td>No log</td>\n    </tr>\n    <tr>\n      <td>8500</td>\n      <td>4.756500</td>\n      <td>No log</td>\n    </tr>\n    <tr>\n      <td>9000</td>\n      <td>4.692200</td>\n      <td>No log</td>\n    </tr>\n    <tr>\n      <td>9500</td>\n      <td>4.551500</td>\n      <td>No log</td>\n    </tr>\n    <tr>\n      <td>10000</td>\n      <td>4.644700</td>\n      <td>No log</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"ğŸ“Š Step 1: loss=10.4946, lr=0.00e+00\nğŸ“Š Step 2: loss=10.5037, lr=1.50e-07\nğŸ“Š Step 3: loss=10.5025, lr=3.00e-07\nğŸ“Š Step 4: loss=10.5013, lr=4.50e-07\nğŸ“Š Step 5: loss=10.4833, lr=6.00e-07\nğŸ“Š Step 6: loss=10.4815, lr=7.50e-07\nğŸ“Š Step 7: loss=10.4621, lr=9.00e-07\nğŸ“Š Step 8: loss=10.4456, lr=1.05e-06\nğŸ“Š Step 9: loss=10.4325, lr=1.20e-06\nğŸ“Š Step 10: loss=10.4055, lr=1.35e-06\nğŸ“Š Step 100: loss=9.2019, lr=1.49e-05\nğŸ“Š Step 200: loss=8.4251, lr=2.99e-05\nğŸ“Š Step 300: loss=8.1103, lr=4.48e-05\nğŸ“Š Step 400: loss=7.8093, lr=5.98e-05\nğŸ“Š Step 500: loss=7.5909, lr=7.48e-05\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\n==================================================\nğŸ“ Step 500 - ç”Ÿæˆæ ·æœ¬:\n==================================================\n  [ä¸­å›½çš„å†å²] â†’ ä¸­å›½çš„å†å²ã€Šã€‹ã€‹ã€‹ã€Šã€‹ ã€Šã€‹ã€Šã€Šã€‹ã€‹ã€‹ã€Š ã€Šã€Šã€Šã€Šã€Šã€Šå² ã€‹ã€‹ã€‹ã€‹ã€‹ã€‹ã€‹ ã€Šã€Šã€Šã€Šã€‹ã€‹ã€Šã€‚ã€Šã€Šã€‹ã€‹ã€‹ã€‹ã€Šã€‚ã€Šã€Š\n  [äººå·¥æ™ºèƒ½æ˜¯] â†’ äººå·¥æ™ºèƒ½æ˜¯åœ¨12å¹´çš„ã€‚ 119çš„                                        \n  [çŸ¥ä¹ä¸Šæœ‰äººé—®] â†’ çŸ¥ä¹ä¸Šæœ‰äººé—®ä¸­å›½åœ¨ä¸€å¼ å¤©ã€‚ä½†æ˜¯ä»–å¥¹ä»–åœ¨ä»–ä»ä¸Šä»–çš„ã€Šç™½ã€‹çš„ã€‚ä»–ä»–åˆã€‚ä»–ä»–ä»–ä¸€è¯´ã€‚â€ä»–ä»–â€ä»–ä»–ä»–æˆ‘ä»–ä»–ä»–ä»–æ¥ä»–ä»–ä»–ä»–ä»–ä»–ä»–\n  [ç§‘å­¦æŠ€æœ¯çš„å‘å±•] â†’ ç§‘å­¦æŠ€æœ¯çš„å‘å±•åœ¨                                                 \n==================================================\n\nğŸ“Š Step 600: loss=7.5024, lr=8.98e-05\nğŸ“Š Step 700: loss=7.3040, lr=1.05e-04\nğŸ“Š Step 800: loss=7.1559, lr=1.20e-04\nğŸ“Š Step 900: loss=6.9714, lr=1.35e-04\nğŸ“Š Step 1000: loss=6.9077, lr=1.50e-04\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\n==================================================\nğŸ“ Step 1000 - ç”Ÿæˆæ ·æœ¬:\n==================================================\n  [ä¸­å›½çš„å†å²] â†’ ä¸­å›½çš„å†å²å›½å›½æ³•é›†å›¢ã€‚\n  [äººå·¥æ™ºèƒ½æ˜¯] â†’ äººå·¥æ™ºèƒ½æ˜¯å¦‚ä½•çœ‹å¾…å›½å†…å…¬å¸å¹³å° å¹´ã€‚                                           \n  [çŸ¥ä¹ä¸Šæœ‰äººé—®] â†’ çŸ¥ä¹ä¸Šæœ‰äººé—®ä¸ºä»€ä¹ˆä¸ºä»€ä¹ˆåœ¨ æœˆ æœˆ æœˆæ—¥æ—¥æ—¥æ—¥æ—¥æ—¥æ—¥æ—¥æ—¥æ—¥æ—¥æ—¥æ—¥æ—¥æ—¥æ—¥æ—¥æ—¥æ—¥æ—¥æ—¥æ—¥æ—¥æ—¥æ—¥æ—¥æ—¥æ—¥æ—¥æ—¥æ—¥æ—¥æ—¥æ—¥æ—¥æ—¥æ—¥æ—¥æ—¥æ—¥æ—¥\n  [ç§‘å­¦æŠ€æœ¯çš„å‘å±•] â†’ ç§‘å­¦æŠ€æœ¯çš„å‘å±•å¦‚ä½•ä¸“åˆ©è€…ã€Œå¦‚ä½•å¦‚ä½•â€œä½ çš„â€œâ€  ã€Œä¸ºä»€ä¹ˆã€Œâ€ã€çš„ã€Œã€Œã€Œã€Œã€ã€ã€ã€Œã€Œã€Œã€Œã€ã€ã€ã€å¹¶ã€Œã€Œã€Œã€Œã€Œã€ã€ã€ã€ã€ã€ã€Œã€Œã€Œã€Œã€Œ\n==================================================\n\nğŸ“Š Step 1100: loss=6.7078, lr=1.65e-04\nğŸ“Š Step 1200: loss=6.6303, lr=1.80e-04\nğŸ“Š Step 1300: loss=6.5175, lr=1.95e-04\nğŸ“Š Step 1400: loss=6.3858, lr=2.10e-04\nğŸ“Š Step 1500: loss=6.1849, lr=2.25e-04\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\n==================================================\nğŸ“ Step 1500 - ç”Ÿæˆæ ·æœ¬:\n==================================================\n  [ä¸­å›½çš„å†å²] â†’ ä¸­å›½çš„å†å²ä¸­å›½åª’ä½“ç½‘ç»œæ–°é—»åœˆåœˆåœˆåœˆåœˆåœˆåœˆåœˆåœˆåœˆåœˆåœˆåœˆåœˆåœˆåœˆåœˆåœˆåœˆåœˆåœˆåœˆåœˆåœˆåœˆåœˆåœˆåœˆåœˆåœˆåœˆåœˆåœˆåœˆåœˆåœˆåœˆåœˆåœˆåœˆåœˆåœˆåœˆåœˆåœˆåœˆ\n  [äººå·¥æ™ºèƒ½æ˜¯] â†’ äººå·¥æ™ºèƒ½æ˜¯ä¸ºä»€ä¹ˆå¯¹å¤§å­¦æ•™è‚²çŸ¥è¯†å’ŒçŸ¥è¯†çš„è®¤å¯å’Œä»·å€¼å‘¢? ä½†æˆ‘ä»¬ç°åœ¨åœ¨æ•™è‚²ä¸­æ˜¯æ•™è‚²è¡Œä¸šçš„æ•™è‚²ã€‚ æ•™è‚²ä¸æ•™è‚²å‘å±• æ•™è‚²æ•™è‚²æ•™è‚²æ•™è‚²æ•™è‚²æ•™è‚²æ•™è‚²æ•™è‚²æ•™è‚²æ•™è‚²æ•™è‚²æ•™è‚²æ•™è‚²æ•™è‚²æ•™è‚²æ•™è‚²æ•™è‚²æ•™è‚²æ•™è‚²\n  [çŸ¥ä¹ä¸Šæœ‰äººé—®] â†’ çŸ¥ä¹ä¸Šæœ‰äººé—®ä¸ºä»€ä¹ˆæœ‰äº›çŸ¥å‹çš„çŸ¥å‹çš„æ¨èå¤§å®¶åˆ†äº«ä¸€ä¸‹æˆ‘çš„å…¬ä¼—å·æˆ–è€…å…¬ä¼—å·çš„å…¬ä¼—å· çš„å›ç­”ã€æ”¶è—çš„ åˆ†äº«çš„â€œ â€çš„â€œç‚¹å‡»çš„â€çš„â€œç‚¹å‡»â€çš„â€œã€æ”¶è—å°â€  è¯·å„ä½å°çš„å…³æ³¨ç‚¹ \n  [ç§‘å­¦æŠ€æœ¯çš„å‘å±•] â†’ ç§‘å­¦æŠ€æœ¯çš„å‘å±•ä½ æœ‰æ²¡æœ‰ä»€ä¹ˆäººçœ‹è°æ€ä¹ˆå‘¢? ç­”æ¡ˆ:ã€ä¸–ç•Œç¤¾ä¼š ä»€ä¹ˆä¸–ç•Œ ç”Ÿå‘½ äººç±»ç¤¾ä¼š äººç±»ç¤¾ä¼š æ˜¯äººç±»ç¤¾ä¼šçš„ æ˜¯ä¸–ç•Œ ç¤¾ä¼šå…³ç³» äººç±»ç¤¾ä¼š ä¸ç¤¾ä¼šçš„ç¾¤ä½“ äººç±»ç¤¾ä¼šã€‚ \n==================================================\n\nğŸ“Š Step 1600: loss=6.0602, lr=2.40e-04\nğŸ“Š Step 1700: loss=6.0488, lr=2.55e-04\nğŸ“Š Step 1800: loss=5.8414, lr=2.70e-04\nğŸ“Š Step 1900: loss=5.7297, lr=2.85e-04\nğŸ“Š Step 2000: loss=5.6643, lr=3.00e-04\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\n==================================================\nğŸ“ Step 2000 - ç”Ÿæˆæ ·æœ¬:\n==================================================\n  [ä¸­å›½çš„å†å²] â†’ ä¸­å›½çš„å†å²å¦‚ä½•è¯„ä»·æ­Œæ‰‹ã€Šå°‘å¹´å¥³ã€‹çš„é«˜é¢œå€¼é«˜?â€œç‹â€ç‹â€å¤§ç‹æ˜¯ç‹å¤§å’Œç‹å¤§ã€ç‹å¤§å’Œç‹å¤§ä¸€èµ·ä¸€èµ·æˆé•¿ã€‚ ç‹å¤§å’Œç‹å¤§ä¸€èµ·æˆé•¿å°±æ˜¯ç‹å¤§ã€ç‹å¤§å’Œç‹\n  [äººå·¥æ™ºèƒ½æ˜¯] â†’ äººå·¥æ™ºèƒ½æ˜¯å¤§å®¶æ€ä¹ˆèµšé’±å¥½ä¹ˆ?                       \n  [çŸ¥ä¹ä¸Šæœ‰äººé—®] â†’ çŸ¥ä¹ä¸Šæœ‰äººé—®ä¸ºä»€ä¹ˆä¸­å›½ç•™å­¦ç”Ÿä¸ä¼šæ­§è§†ä¸­å›½ç•™å­¦ç”Ÿä¼šæ­§è§†ä¸­å›½ç•™å­¦ç”Ÿ?å› ä¸ºä¸­å›½ç•™å­¦ç”Ÿåœ¨ç•™å­¦çš„æ—¶å€™åº”è¯¥è¦å’Œæ­§è§†ä¸­å›½ç•™å­¦ç”Ÿã€‚\n  [ç§‘å­¦æŠ€æœ¯çš„å‘å±•] â†’ ç§‘å­¦æŠ€æœ¯çš„å‘å±•å¦‚ä½•ç†è§£ å†™è‡ªå·±æƒ³è¦çš„æ€ç»´æ€ç»´ç»“æ„       å†™ä¸€ä¸ªäººå†™è‡ªå·±å†™çš„ä¸œè¥¿  å°±æ˜¯  æ¯”å¦‚å†™åˆ°æ–‡ç« çš„          å†™å†™ å†™å†™  å†™\n==================================================\n\nğŸ“Š Step 2100: loss=5.5654, lr=3.00e-04\nğŸ“Š Step 2200: loss=5.6012, lr=3.00e-04\nğŸ“Š Step 2300: loss=5.5082, lr=3.00e-04\nğŸ“Š Step 2400: loss=5.4586, lr=3.00e-04\nğŸ“Š Step 2500: loss=5.4908, lr=2.99e-04\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\n==================================================\nğŸ“ Step 2500 - ç”Ÿæˆæ ·æœ¬:\n==================================================\n  [ä¸­å›½çš„å†å²] â†’ ä¸­å›½çš„å†å²å¦‚ä½•ä»å†å²è¿›ç¨‹ä¸­å®ç°ã€æœ€æœ¬è´¨çš„æŒ‘æˆ˜ã€å¦‚ä½•åˆ©ç”¨ã€å…¨é¢ã€å…¨é¢ã€å…¨é¢ã€å…¨é¢ã€å…¨é¢ã€å…¨é¢ã€å…¨é¢ã€å…¨é¢ã€å…¨é¢ã€å…¨é¢ã€å…¨é¢ã€å…¨é¢ã€å…¨é¢ã€å…¨é¢ã€å…¨é¢å…¨é¢ã€å…¨é¢ã€å…¨é¢å…¨é¢\n  [äººå·¥æ™ºèƒ½æ˜¯] â†’ äººå·¥æ™ºèƒ½æ˜¯åœ¨                                                 \n  [çŸ¥ä¹ä¸Šæœ‰äººé—®] â†’ çŸ¥ä¹ä¸Šæœ‰äººé—®ä¸ºä»€ä¹ˆæ„Ÿè§‰åœ¨è¿™æ–¹é¢è®¾è®¡ä¸Šæœ‰ä»€ä¹ˆç¼ºç‚¹å’Œç¼ºç‚¹å°±å¾ˆå¤šäº†ã€‚                                    \n  [ç§‘å­¦æŠ€æœ¯çš„å‘å±•] â†’ ç§‘å­¦æŠ€æœ¯çš„å‘å±•ã€Šç¥ç¥ç¥ç¥ç¥ç¥ç¥ç¥ç¥ç¥ç¥ç¥ç¥ç¥ç¥ç¥ç¥ç¥ç¥ç¥ç¥ç¥ç¥ç¥ç¥ç¥ç¥ç¥ç¥ç¥ç¥ç¥ç¥ç¥ç¥ã€‚ã€ç¥ç¥ç¥ç¥ç¥ç¥ç¥ç¥ç¥ç¥ç¥ç¥\n==================================================\n\nğŸ“Š Step 2600: loss=5.3410, lr=2.99e-04\nğŸ“Š Step 2700: loss=5.3969, lr=2.99e-04\nğŸ“Š Step 2800: loss=5.3039, lr=2.98e-04\nğŸ“Š Step 2900: loss=5.4178, lr=2.98e-04\nğŸ“Š Step 3000: loss=5.3432, lr=2.97e-04\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\n==================================================\nğŸ“ Step 3000 - ç”Ÿæˆæ ·æœ¬:\n==================================================\n  [ä¸­å›½çš„å†å²] â†’ ä¸­å›½çš„å†å²ã€Šä¸‰å›½å¿—Â·ä¸‰å›½å¿—Â·ä¸‰å›½å¿—Â·èµµé•¿ä¹‹ Â·ä¸‰å›½å¿—Â·ä¸‰å›½å¿—Â·ä¸‰å›½å¿—Â·ä¸‰å›½å¿—Â·ä¸‰å›½å¿—Â·ä¸‰å›½å¿—Â·ä¸‰å›½å¿—Â·ä¸‰å›½å¿—Â·ä¸‰å›½å¿—Â·ä¸‰å›½å¿—Â·ä¸‰å›½å¿—Â·ä¸‰å›½å¿—Â·ä¸‰å›½å¿—Â·ä¸‰å›½å¿—Â·ä¸‰å›½å¿—Â·ä¸‰å›½å¿—Â·ä¸‰å›½å¿—Â·ä¸‰å›½å¿—Â·Â·ä¸‰å›½å¿—\n  [äººå·¥æ™ºèƒ½æ˜¯] â†’ äººå·¥æ™ºèƒ½æ˜¯å¤§å®¶ç”¨è½¦æ—¶é—´å¤šä¸€ç‚¹æ—¶é—´å»ç ”ç©¶ã€‚                                  \n  [çŸ¥ä¹ä¸Šæœ‰äººé—®] â†’ çŸ¥ä¹ä¸Šæœ‰äººé—®ä¸Šæµ·çš„æ‘„å½±å’¨è¯¢å²—çš„é”€å”®äººå‘˜æœ‰å“ªäº›å¸®åŠ©å’Œå»ºè®®çš„ä¸šåŠ¡äººå‘˜å—?é¦–å…ˆ  å¾ˆå¤šä¸“ä¸šçš„æ‘„å½±ä¸“ä¸šçš„å°±ä¸šç¯å¢ƒæ¯”è¾ƒæµ“åšä¸”æœ‰å®ä¹ å²—ä½çš„åŒå­¦éƒ½æ˜¯ä¸é”™çš„é€‰æ‹©   ä»¥æˆ‘æ‰€çŸ¥çš„è¡Œä¸šä¸ºä¾‹ã€‚    \n  [ç§‘å­¦æŠ€æœ¯çš„å‘å±•] â†’ ç§‘å­¦æŠ€æœ¯çš„å‘å±•ä¸­å›½ç”µå½±æœ‰é™å…¬å¸å’Œä¸­å›½ç”µå½±æœ‰é™å…¬å¸æœ‰ä»€ä¹ˆåŒºåˆ«? åŒ—äº¬ç”µå½±æœ‰é™å…¬å¸çš„æˆç«‹å’Œå‘å±•ç ”ç©¶é™¢æœ‰é™å…¬å¸ å‡ºå“çš„æ˜¯ä¸­å›½ç”µå½±å…¬å¸å‘å±•ç ”ç©¶é™¢çš„æˆç«‹å’Œå‘å±•ç ”ç©¶é™¢åˆä½œè”åˆåˆä½œåŠå­¦åŸºåœ°çš„ä¸­å›½ç”µå½±å…¬å¸ã€‚ å‡ºå“çš„æ˜¯ä¸­å›½ç”µå½±å…¬å¸å‘å±•ç ”ç©¶é™¢è”åˆ\n==================================================\n\nğŸ“Š Step 3100: loss=5.3443, lr=2.97e-04\nğŸ“Š Step 3200: loss=5.2295, lr=2.96e-04\nğŸ“Š Step 3300: loss=5.2571, lr=2.95e-04\nğŸ“Š Step 3400: loss=5.1430, lr=2.94e-04\nğŸ“Š Step 3500: loss=5.1781, lr=2.94e-04\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\n==================================================\nğŸ“ Step 3500 - ç”Ÿæˆæ ·æœ¬:\n==================================================\n  [ä¸­å›½çš„å†å²] â†’ ä¸­å›½çš„å†å²æ€ä¹ˆè¯„ä»·ã€Šç§¦æ—¶æ˜æœˆã€‹å¤§çƒ­åœ¨ä¸–æ—¶çš„ã€Šå¤©ä¹‹é—¨ã€‹ä¸­ä¸ºä½•è¯´â€œè¿™æ˜¯ä¸¤ä»£â€çš„? é¦–å…ˆç»“è®ºæ¥è¯´è¯´åœ¨ä¸¤ä»£åœ¨ä¸–å‰å››ä»£æ˜¯æ²¡ç®—ã€‚ ä¸€ã€ä»¥ç§¦æ—¶æ˜æœˆä¸ºä¸»ä½“çš„\n  [äººå·¥æ™ºèƒ½æ˜¯] â†’ äººå·¥æ™ºèƒ½æ˜¯ä¸ºä»€ä¹ˆã€Šå†°ä¸ç«ä¹‹æ­Œã€‹çš„åŠ¨ç”»å’Œã€Šå†°ä¸ç«ä¹‹æ­Œã€‹çš„åŠ¨ç”»ç›¸æ¯”ä¼šæ›´å¥½å‘å±•? \n  [çŸ¥ä¹ä¸Šæœ‰äººé—®] â†’ çŸ¥ä¹ä¸Šæœ‰äººé—®å¦‚ä½•çœ‹å¾…ä¸­å›½æ”¿æ³•å¤§å­¦ä¸ä¸­å›½æ”¿æ³•å¤§å­¦åˆå¹¶è€Œæ¥ä¸€ç§ä»€ä¹ˆæ ·çš„å…³ç³»å‘¢?                         ä¸­å›½æ”¿æ³•å¤§å­¦        \n  [ç§‘å­¦æŠ€æœ¯çš„å‘å±•] â†’ ç§‘å­¦æŠ€æœ¯çš„å‘å±•å¦‚ä½•çœ‹å¾…æ­¦æ±‰ç†å·¥å¤§å­¦åšå£«ç”Ÿæºä¸æ–­ä¸ºå­¦ç”ŸæœåŠ¡çš„ã€Œå°±ä¸šã€è€Œåšå‡ºçš„å†³ç­–å‘¢? äºŒã€å…³äºâ€œå·¥â€æ”¿ç­– å·¥æ˜¯ä¸å·¥çš„ã€Œäº’è”ç½‘ã€ å·¥çš„ã€Œä¸­äº§ã€å’Œã€Œä¸­äº§ã€çš„æ”¿ç­–\n==================================================\n\nğŸ“Š Step 3600: loss=5.1424, lr=2.93e-04\nğŸ“Š Step 3700: loss=5.0700, lr=2.92e-04\nğŸ“Š Step 3800: loss=5.1206, lr=2.91e-04\nğŸ“Š Step 3900: loss=5.0558, lr=2.90e-04\nğŸ“Š Step 4000: loss=5.0980, lr=2.89e-04\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\n==================================================\nğŸ“ Step 4000 - ç”Ÿæˆæ ·æœ¬:\n==================================================\n  [ä¸­å›½çš„å†å²] â†’ ä¸­å›½çš„å†å²å¦‚æœå°†è¦å°†è¦å°†è¦å°†è¦å°†è¦å°†è¦å°†è¦å°†è¦å°†è¦å°†è¦å°†è¦å°†è¦å°†è¦å°†è¦å°†è¦å°†è¦å°†è¦å°†è¦åšçš„æ˜¯å°†è¦å°†è¦å°†è¦å°†è¦å°†è¦å°†\n  [äººå·¥æ™ºèƒ½æ˜¯] â†’ äººå·¥æ™ºèƒ½æ˜¯æœ‰å“ªäº›è½¯ä»¶æ¯”è¾ƒå¥½ç”¨çš„è½¯ä»¶?æ¨èè½¯ä»¶è½¯ä»¶æ¨èç³»ç»Ÿã€æ™ºèƒ½è¯­éŸ³è½¯ä»¶ã€æ™ºèƒ½è¯­éŸ³è½¯ä»¶ç­‰è½¯ä»¶è½¯ä»¶è½¯ä»¶æ˜¯å›½å†…æ¯”è¾ƒå¸¸è§çš„è½¯ä»¶äº†ã€‚ è½¯ä»¶è½¯ä»¶è½¯ä»¶æ¨èç³»ç»Ÿæ˜¯è½¯ä»¶è½¯ä»¶è½¯ä»¶è½¯ä»¶è½¯ä»¶è½¯ä»¶è½¯ä»¶çš„é¦–é€‰è½¯ä»¶è½¯ä»¶äº†ã€‚\n  [çŸ¥ä¹ä¸Šæœ‰äººé—®] â†’ çŸ¥ä¹ä¸Šæœ‰äººé—®ä¸ºä»€ä¹ˆå¾ˆå¤šäººè¯´æ±½è½¦å‘åŠ¨æœºçš„å‘åŠ¨æœºå‘åŠ¨æœºæ²¡æœ‰å‘åŠ¨æœºå‘åŠ¨æœºã€‚é‚£ä¹ˆå¦‚æœå‘åŠ¨æœºå‘åŠ¨æœºçš„å‘åŠ¨æœºå‘åŠ¨æœºæ€§èƒ½å¾ˆå¼±æ€ä¹ˆåŠ?ä¸ºä»€ä¹ˆè½¦å†µå¥½äº›?è½¦å†µå¥½äº›?é‚£ä¹ˆå‘åŠ¨æœºçš„å‘åŠ¨æœºå’Œå‘åŠ¨æœºæ€§èƒ½çš„å·®åˆ«? å‘åŠ¨æœºçš„å‘åŠ¨æœºæ€§èƒ½\n  [ç§‘å­¦æŠ€æœ¯çš„å‘å±•] â†’ ç§‘å­¦æŠ€æœ¯çš„å‘å±•å¦‚ä½•è¯„ä»· 2015 å¹´ 4 æœˆ 6 æ—¥ç¾è‚¡æš´è·Œ 8 ç‚¹ ç¾è‚¡æš´è·Œ 8 æœˆ 9 7 æ—¥ç¾è‚¡æš´è·Œ 8 æœˆ 6 æ—¥ç¾è‚¡é«˜ç©ºç†”æ–­ 9 æœˆ 9\n==================================================\n\nğŸ“Š Step 4100: loss=5.0778, lr=2.88e-04\nğŸ“Š Step 4200: loss=5.0445, lr=2.86e-04\nğŸ“Š Step 4300: loss=4.9929, lr=2.85e-04\nğŸ“Š Step 4400: loss=5.0607, lr=2.84e-04\nğŸ“Š Step 4500: loss=4.9874, lr=2.83e-04\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\n==================================================\nğŸ“ Step 4500 - ç”Ÿæˆæ ·æœ¬:\n==================================================\n  [ä¸­å›½çš„å†å²] â†’ ä¸­å›½çš„å†å²ã€ŠåŸç¥ã€‹è¿™æ¬¾æ¸¸æˆä»ä»€ä¹ˆæ—¶å€™èµ·å°±èƒ½çœ‹å‡ºæ˜¯å“ªä¸€å¹´çš„å‘¢?                                   \n  [äººå·¥æ™ºèƒ½æ˜¯] â†’ äººå·¥æ™ºèƒ½æ˜¯ä¸ºä»€ä¹ˆ 100 åèƒŒä¾§å¼¯çš„ 50 åèƒŒä¾§å¼¯çš„ 50 åèƒŒä¾§å¼¯çš„ 50 åèƒŒä¾§å¼¯çš„ 100 åèƒŒä¾§å¼¯çš„ 50 åèƒŒä¾§å¼¯çš„ \n  [çŸ¥ä¹ä¸Šæœ‰äººé—®] â†’ çŸ¥ä¹ä¸Šæœ‰äººé—®ã€Œä¸–ç•Œå¤§è¶‹åŠ¿ã€æŒ‡çš„èµ°åŠ¿ã€‚è¯¥è¶‹åŠ¿å’Œä¸–ç•Œè¶‹åŠ¿èµ°åŠ¿çš„èµ°åŠ¿é€šå¸¸ä¸ºä»¥ä¸‹ç±»å‹ã€‚å…¶ä¸­æŒ‡æ•°å‹æŒ‡æ•°å’Œæ²ªæ·± 50 ä¸ªã€‚  ä»£è¡¨æŒ‡æ•°å‹æŒ‡æ•°å’Œæ²ªæ·± 40 ä¸ªã€‚  \n  [ç§‘å­¦æŠ€æœ¯çš„å‘å±•] â†’ ç§‘å­¦æŠ€æœ¯çš„å‘å±•ä¸ºä»€ä¹ˆè¯´ä¸­å›½çŸ³æ²¹çŸ³æ²¹ä»·æ ¼ä¼šä¸‹é™?ä¸ºä»€ä¹ˆè¿™ä¹ˆè¯´?ä¸­å›½çŸ³æ²¹ä»·æ ¼ä¸‹è·Œä¼šå¤§å‘¢?å› ä¸ºä¸­å›½çŸ³æ²¹ä»·æ ¼ä¸Šæ¶¨ä¼šå¤§å—?\n==================================================\n\nğŸ“Š Step 4600: loss=4.9971, lr=2.81e-04\nğŸ“Š Step 4700: loss=4.9842, lr=2.80e-04\nğŸ“Š Step 4800: loss=5.0353, lr=2.78e-04\nğŸ“Š Step 4900: loss=5.0134, lr=2.77e-04\nğŸ“Š Step 5000: loss=4.9738, lr=2.75e-04\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\n==================================================\nğŸ“ Step 5000 - ç”Ÿæˆæ ·æœ¬:\n==================================================\n  [ä¸­å›½çš„å†å²] â†’ ä¸­å›½çš„å†å²ä¸ºä»€ä¹ˆä¸­å›½æ²¡æœ‰ä¸€ä¸ªç»Ÿä¸€çš„ç‹¬ç«‹ç«™é˜Ÿæ¥å‘å±•? å› ä¸ºæ²¡æœ‰ä¸€ä¸ªç»Ÿä¸€çš„ç«™é˜Ÿ                               \n  [äººå·¥æ™ºèƒ½æ˜¯] â†’ äººå·¥æ™ºèƒ½æ˜¯ä¸ºä»€ä¹ˆç°åœ¨å¾ˆå°‘äººç”¨ç›—ç‰ˆçš„è½¯ä»¶ç”¨ç›—ç‰ˆè½¯ä»¶? ? ç›—ç‰ˆè½¯ä»¶å‘¢ è½¯ä»¶ä¸‹è½½çš„è½¯ä»¶ä¸‹è½½çš„è½¯ä»¶ ä¸‹è½½çš„è½¯ä»¶ä¸‹è½½è½¯ä»¶ ä¸‹è½½è½¯ä»¶ä¸‹è½½çš„è½¯ä»¶ ä¸‹è½½è½¯ä»¶ ä¸‹è½½è½¯ä»¶ ä¸‹è½½è½¯ä»¶ ä¸‹è½½è½¯ä»¶\n  [çŸ¥ä¹ä¸Šæœ‰äººé—®] â†’ çŸ¥ä¹ä¸Šæœ‰äººé—®æœ‰æ— è§£çš„å’–å•¡å› æœ‰å“ªäº›??å’–å•¡è±†?å’–å•¡å› é£å‘³çš„ç‹¬ç‰¹æ€§?å£æ„Ÿå’Œé£å‘³?é£å‘³æ›´ç‹¬ç‰¹??            é£å‘³:         \n  [ç§‘å­¦æŠ€æœ¯çš„å‘å±•] â†’ ç§‘å­¦æŠ€æœ¯çš„å‘å±•å¦‚ä½•åœ¨å¤§å­¦é‡Œå­¦ä¹ é’¢ç´çš„æ•™å­¦æ–¹å¼?å¦‚æœå­¦ä¹ é’¢ç´æ•™å­¦çš„è¯çš„è¯ã€‚å¦‚æœä½ éœ€è¦ä¸€ä¸ªç®€å•çš„å­¦ä¹ ã€‚\n==================================================\n\nğŸ“Š Step 5100: loss=4.8520, lr=2.73e-04\nğŸ“Š Step 5200: loss=4.8389, lr=2.72e-04\nğŸ“Š Step 5300: loss=4.9414, lr=2.70e-04\nğŸ“Š Step 5400: loss=4.8937, lr=2.68e-04\nğŸ“Š Step 5500: loss=4.7972, lr=2.66e-04\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\n==================================================\nğŸ“ Step 5500 - ç”Ÿæˆæ ·æœ¬:\n==================================================\n  [ä¸­å›½çš„å†å²] â†’ ä¸­å›½çš„å†å²ç”µå½±ã€Šè‡´é’æ˜¥ã€‹çš„ç»­é›†æ˜¯ä»€ä¹ˆç»“å±€å‘¢?\n  [äººå·¥æ™ºèƒ½æ˜¯] â†’ äººå·¥æ™ºèƒ½æ˜¯ã€Šé»‘æš—ä¹‹å…‰ã€‹ä¸­çš„è§’è‰²ä¸ºä»€ä¹ˆä¼šå˜æˆè¿™æ ·çš„åå­—? ?  ã€Œ ã€ ã€Œè¿™æ˜¯æˆ‘ä»¬å°æ—¶å€™çš„è®°å¿†å—?ã€  ã€Œä½ ä¸€å®šä¸é«˜å…´ã€ ã€Œå¯¹å§?ã€  ã€Œè¿™æ˜¯æˆ‘ä»¬å°æ—¶å€™è®°å¿†\n  [çŸ¥ä¹ä¸Šæœ‰äººé—®] â†’ çŸ¥ä¹ä¸Šæœ‰äººé—®å¦‚ä½•çœ‹å¾…æ•™è‚²éƒ¨å°†ã€Œå°†ä¸è½å¸å›½ã€è§†ä¸ºã€Œä¸è½å¸å›½ã€çš„åšæ³•?ã€Œä¸è½å¸å›½ã€è¿™ä¸ªè§‚ç‚¹æ˜¯ä¸æ˜¯æœ‰è¯¯å—?\n  [ç§‘å­¦æŠ€æœ¯çš„å‘å±•] â†’ ç§‘å­¦æŠ€æœ¯çš„å‘å±•ä¸ºä»€ä¹ˆå¾ˆå¤šäººä¹°å¥¢ä¾ˆå“æ²¡æœ‰æ„è¯†åˆ°å¥¢ä¾ˆå“çš„æ²¡è½å—?    \n==================================================\n\nğŸ“Š Step 5600: loss=4.9209, lr=2.65e-04\nğŸ“Š Step 5700: loss=4.8619, lr=2.63e-04\nğŸ“Š Step 5800: loss=4.8219, lr=2.61e-04\nğŸ“Š Step 5900: loss=4.8983, lr=2.59e-04\nğŸ“Š Step 6000: loss=4.8921, lr=2.57e-04\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\n==================================================\nğŸ“ Step 6000 - ç”Ÿæˆæ ·æœ¬:\n==================================================\n  [ä¸­å›½çš„å†å²] â†’ ä¸­å›½çš„å†å²ä¸ºä»€ä¹ˆä¸­å›½åœ¨æ¬§ç¾å¦‚æ­¤å‘è¾¾çš„å›½å®¶é‡Œå´å¾ˆå°‘äººèƒ½åœ¨å…¶ä»–å›½å®¶æ‰“è´¥æ—¥æœ¬?1. ä¸­å›½äººæœ€æ“…é•¿çš„å°±æ˜¯æ—¥æœ¬äººã€‚ 2ã€ ä¸­å›½äººæœ€å–œæ¬¢æ—¥æœ¬ã€‚ æ—¥æœ¬äººæœ€æ“…é•¿çš„å°±æ˜¯è‹±å›½äººã€‚ æ—¥æœ¬äººæœ€æ“…é•¿çš„å°±æ˜¯æ—¥æœ¬äººã€‚ ä¸­å›½äºº\n  [äººå·¥æ™ºèƒ½æ˜¯] â†’ äººå·¥æ™ºèƒ½æ˜¯å¦‚ä½•çœ‹å¾… 2019 å¹´ 12 æœˆ 18 æ—¥æ™šçš„ 11 æ—¥å‡Œæ™¨å‘ç”Ÿçš„ 11 æ—¥ä¸­åˆ 6 ç‚¹å·¦å³çš„åˆåå‘ç”Ÿçš„ 12 ç‚¹å·¦å³çš„åˆåå‘ç”Ÿçš„ 12 ç‚¹å·¦å³çš„åˆåå‘ç”Ÿçš„\n  [çŸ¥ä¹ä¸Šæœ‰äººé—®] â†’ çŸ¥ä¹ä¸Šæœ‰äººé—®å¦‚ä½•è¯„ä»·ã€ŒçŸ¥ä¹ç”¨æˆ·å¯¹çŸ¥è¯†ä»˜è´¹ pp ä¼šæé«˜å—ã€è¿™ä¸€è¯é¢˜ã€‚ ã€Œé«˜èµå›ç­”ã€æ˜¯æŒ‡ã€Œæ–‡ç« å†…å®¹ã€åœ¨ç‰¹å®šåœºåˆä¸­åŒ…å«çš„å†…å®¹åŠæ–‡ç« ã€‚æ‰€ä»¥å›ç­”æ—¶åº”è¯¥æœ‰é«˜è´¨é‡å›ç­”ã€‚ ã€Œé«˜èµ\n  [ç§‘å­¦æŠ€æœ¯çš„å‘å±•] â†’ ç§‘å­¦æŠ€æœ¯çš„å‘å±•æœ‰è°çš„æ¢¦æƒ³å‘¢?æœ‰è°çš„æ¢¦æƒ³å‘¢?æƒ³äº†å¾ˆä¹…æƒ³å¥½æƒ³è¦çš„æˆåŠŸä¸æ¢¦æƒ³å§(âŠ™â–½âŠ™)âœ§\n==================================================\n\nğŸ“Š Step 6100: loss=4.9204, lr=2.55e-04\nğŸ“Š Step 6200: loss=4.8723, lr=2.52e-04\nğŸ“Š Step 6300: loss=4.8776, lr=2.50e-04\nğŸ“Š Step 6400: loss=4.8191, lr=2.48e-04\nğŸ“Š Step 6500: loss=4.7710, lr=2.46e-04\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\n==================================================\nğŸ“ Step 6500 - ç”Ÿæˆæ ·æœ¬:\n==================================================\n  [ä¸­å›½çš„å†å²] â†’ ä¸­å›½çš„å†å²å¦‚ä½•è¯„ä»·ã€Œå°ç±³æ‰‹æœº æ¯” 6 è¿˜è´µ 3 ? ?ã€      \n  [äººå·¥æ™ºèƒ½æ˜¯] â†’ äººå·¥æ™ºèƒ½æ˜¯å¦‚ä½•è¯„ä»· 2015 å¹´ 8 æœˆ 10 æ—¥ 6 æœˆ 7 æ—¥å‘å¸ƒçš„æœ€æ–° 7 æœˆä»½å…¬å¸ƒçš„æœ€æ–°è´¢æŠ¥æ•°æ® 7 æœˆä»½å…¬å¸ƒçš„è´¢æŠ¥æ•°æ®ã€‚ æœ¬æ¬¡è´¢æŠ¥æ•°æ®ä¸º2019å¹´4\n  [çŸ¥ä¹ä¸Šæœ‰äººé—®] â†’ çŸ¥ä¹ä¸Šæœ‰äººé—®ä½ æœ€ä¸å–œæ¬¢çš„æ˜¯ä»€ä¹ˆäººå—? ?? ? ? ? ? ? ? ? ?  ? ?  ? ? ?? ? ? ? ? ?\n  [ç§‘å­¦æŠ€æœ¯çš„å‘å±•] â†’ ç§‘å­¦æŠ€æœ¯çš„å‘å±•æ€æ ·çœ‹ä¸Š 12306 çš„æ™®åŠå’Œæ™®åŠ? ä¸Šæ±½å¤§ä¼— ä¸Šæ±½å¤§ä¼— ä¸Šæ±½å¤§ä¼— ä¸Šæ±½å¤§ä¼— ä¸Šæ±½å¤§ä¼— ä¸Šæ±½å¤§ä¼— ä¸Šæ±½å¤§ä¼—ã€ä¸Šæ±½å¤§ä¼— ä¸Šæ±½å¤§ä¼— ä¸Šæ±½\n==================================================\n\nğŸ“Š Step 6600: loss=4.8219, lr=2.44e-04\nğŸ“Š Step 6700: loss=4.8327, lr=2.41e-04\nğŸ“Š Step 6800: loss=4.8289, lr=2.39e-04\nğŸ“Š Step 6900: loss=4.7886, lr=2.37e-04\nğŸ“Š Step 7000: loss=4.9133, lr=2.34e-04\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\n==================================================\nğŸ“ Step 7000 - ç”Ÿæˆæ ·æœ¬:\n==================================================\n  [ä¸­å›½çš„å†å²] â†’ ä¸­å›½çš„å†å²æœ‰æ²¡æœ‰ä¸€ä¸ªæ¯” 7 æœˆ 19 æ—¥çš„ä¸­æ–‡ç¿»è¯‘è½¯ä»¶?å¥½éš¾? ?? ? ? ? ? ? ? ? ? ? ? ? ? ? ?\n  [äººå·¥æ™ºèƒ½æ˜¯] â†’ äººå·¥æ™ºèƒ½æ˜¯ç”µå½±ã€Šä¸‰ä½“ã€‹ç³»åˆ—ä¸­å“ªä¸ªå¥³å¼ºäººè¦è·Ÿä¸‰ä½“å°è¯´ç³»åˆ—ä¸€æ ·çš„å‰§æƒ…æ¯”è¾ƒæœ‰è¶£?æˆ‘å†™ä¸‰ä½“ç³»åˆ—æ—¶æ˜¯å†™ä¸‰ä½“ç³»åˆ—çš„ã€‚ ä¸‰ä½“å°è¯´ç³»åˆ— ä¸‰ä½“ç³»åˆ—ä¸­å‡ ä¸ªå¥³å¼ºäººéƒ½æ˜¯å¥³å¼ºäººç”·ä¸»ã€‚ ä¸‰ä½“\n  [çŸ¥ä¹ä¸Šæœ‰äººé—®] â†’ çŸ¥ä¹ä¸Šæœ‰äººé—®ä¸ºä»€ä¹ˆã€Šèµ›åšæœ‹å…‹2077ã€‹å‘å¸ƒä»¥åä¼šå‡ºæ–°æ¸¸æˆã€Šèµ›åšæœ‹å…‹2077ã€‹å‘å¸ƒåä¼šå‡ºæ–°åŠ¨ä½œã€Šèµ›åšæœ‹å…‹2077ã€‹ç‰ˆå—?ä½ çŒœè°åœ¨åè¾¹ç©å—? èµ›åšæœ‹å…‹æ¸¸æˆå‘å¸ƒä¹‹åä¼šè¢«æ›´å¤šçš„äººçœ‹åˆ° èµ›åšæœ‹å…‹æ¸¸æˆå‘å”®ä¹‹åçš„é”€é‡åº”è¯¥ä¼š\n  [ç§‘å­¦æŠ€æœ¯çš„å‘å±•] â†’ ç§‘å­¦æŠ€æœ¯çš„å‘å±•ã€Šæ— æã€‹å’Œã€Šçº¢æ¥¼æ¢¦ã€‹çš„å·®åˆ«æœ‰å“ªäº›?ä¸ºä»€ä¹ˆæ˜¯ä¸‰é›†ä¸¤é›†çš„ã€Šçº¢æ¥¼æ¢¦ã€‹çš„å·®åˆ«å¾ˆå¤§å‘¢?çº¢æ¥¼æ¢¦ çº¢æ¥¼æ¢¦ çº¢æ¥¼æ¢¦ çº¢æ¥¼æ¢¦ çº¢æ¥¼æ¢¦ çº¢æ¥¼æ¢¦ çº¢æ¥¼æ¢¦ çº¢æ¥¼æ¢¦ çº¢æ¥¼æ¢¦ çº¢æ¥¼æ¢¦ çº¢æ¥¼æ¢¦ çº¢æ¥¼æ¢¦\n==================================================\n\nğŸ“Š Step 7100: loss=4.8012, lr=2.32e-04\nğŸ“Š Step 7200: loss=4.6910, lr=2.29e-04\nğŸ“Š Step 7300: loss=4.8394, lr=2.27e-04\nğŸ“Š Step 7400: loss=4.8378, lr=2.24e-04\nğŸ“Š Step 7500: loss=4.7616, lr=2.22e-04\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\n==================================================\nğŸ“ Step 7500 - ç”Ÿæˆæ ·æœ¬:\n==================================================\n  [ä¸­å›½çš„å†å²] â†’ ä¸­å›½çš„å†å²å¦‚ä½•çœ‹å¾…ä¸­å›½å°†æˆç«‹ 9 å¹´å†…ç¾å›½å›½å€ºäº¤æ˜“å¸‚åœºå¯¹æˆ‘å›½çš„é‡‘èå¸‚åœºæœ‰ä½•å½±å“?  ä¸­å›½è¯åˆ¸å¸‚åœºçš„å¤§å¥½äºä¸Šä¸ªä¸–çºª90å¹´ä»£çš„ç¾å›½èµ„æœ¬å¸‚åœºå¯¹æˆ‘å›½çš„æŠ•èµ„ä»·å€¼çš„å·¨å¤§å½±å“ã€‚   æˆ‘å›½çš„\n  [äººå·¥æ™ºèƒ½æ˜¯] â†’ äººå·¥æ™ºèƒ½æ˜¯ã€Šé¾™ç ã€‹é‡Œçš„çªçªæ€ä¹ˆæ­»çš„å‘¢?çªçªæ²¡æœ‰æ­»è¿‡å¤šå°‘æ¬¡äº†ã€‚åœ¨é¾™ç ä¸­çªçªå’Œçªçªéƒ½æ˜¯å› ä¸ºçªçªçªæ­»å»è€Œå¤æ´»çš„ã€‚çªçªæ˜¯è¢«çªçªæ‰“è´¥çš„ã€‚çªçªçª\n  [çŸ¥ä¹ä¸Šæœ‰äººé—®] â†’ çŸ¥ä¹ä¸Šæœ‰äººé—®å¦‚ä½•è‡ªå­¦å’Œè‡ªå­¦?å¦‚ä½•è¿›è¡Œè‡ªå­¦?è‡ªå­¦æ•™ææœ‰ä»€ä¹ˆæ¨èå—?å­¦ä¹ æ–¹æ³•æœ‰å“ªäº›å‚è€ƒä¹¦ã€æ•™æã€ä¹¦ç±å’ŒéŸ³é¢‘èµ„æºã€ä¹¦ç±å’Œä¹ é¢˜ç­‰ç­‰ã€‚å­¦ä¹ æ–¹æ³•æœ‰å“ªäº›å‘¢? è‡ªå­¦æ–¹æ³•æœ‰å“ªäº›å‘¢? è‡ªå­¦æ•™ææœ‰å“ªäº›? è‡ªå­¦\n  [ç§‘å­¦æŠ€æœ¯çš„å‘å±•] â†’ ç§‘å­¦æŠ€æœ¯çš„å‘å±•å¦‚ä½•è¯„ä»·ã€Šæµ·è´¼ç‹ã€‹ä¸­çš„å½¢è±¡ä¸å½¢è±¡çš„è®¾è®¡? ä»¥åŠå¦‚ä½•ä½“ç°æµ·è´¼ç‹ä¸­çš„å½¢è±¡ä¸å½¢è±¡ æµ·è´¼ä¸­çš„å½¢è±¡ä¸å½¢è±¡çš„è®¾è®¡ æµ·è´¼ä¸­çš„å½¢è±¡ä¸å½¢è±¡æ˜¯ä¸¤ä¸ªä¸»é¢˜ æµ·è´¼ä¸­çš„å½¢è±¡ä¸å½¢è±¡æ˜¯ä¸¤ä¸ªä¸»é¢˜ æµ·è´¼ä¸­çš„å½¢è±¡ä¸å½¢è±¡\n==================================================\n\nğŸ“Š Step 7600: loss=4.7644, lr=2.19e-04\nğŸ“Š Step 7700: loss=4.6689, lr=2.16e-04\nğŸ“Š Step 7800: loss=4.7572, lr=2.14e-04\nğŸ“Š Step 7900: loss=4.7546, lr=2.11e-04\nğŸ“Š Step 8000: loss=4.6352, lr=2.08e-04\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\n==================================================\nğŸ“ Step 8000 - ç”Ÿæˆæ ·æœ¬:\n==================================================\n  [ä¸­å›½çš„å†å²] â†’ ä¸­å›½çš„å†å²ä¸ºä»€ä¹ˆçŸ¥ä¹ç°åœ¨éƒ½æ”¯æŒ 12 ä¸ªå›½å®¶çš„ 12 å¼ºçš„æ™®é€šè¯å’Œæ™®é€šè¯? é‚£ä¸ºä»€ä¹ˆå…¶ä»–è¯­è¨€è¿˜è¦æ”¯æŒ 12 ä¸ªå›½å®¶å‘¢ è¿™è¿˜ç”¨ä¸ç€å‘¢ è¯´ç‚¹ä»€ä¹ˆ 1. ä¸­å›½äººçš„æ™®é€šè¯é—®é¢˜ è¯´\n  [äººå·¥æ™ºèƒ½æ˜¯] â†’ äººå·¥æ™ºèƒ½æ˜¯å¦‚ä½•è¯„ä»·å‘¨æ·±ä¸ºæ­Œæ‰‹å‘å£°çš„å…³äºç‰ˆæƒçº çº·çš„äº‰è®®è¯é¢˜ å‘¨æ·±å”±çš„ã€Šæ­Œæ‰‹ã€‹é‡Œæ²¡æœ‰å”±åˆ°å‘¨æ·±å”±æ­Œçš„è¿™ä¸€è¡Œä¸º å‘¨æ·±å”±çš„ã€Šæ­Œæ‰‹ã€‹å’Œã€Šæ­Œæ‰‹ã€‹ä¸­çš„æ­Œæ‰‹ä¸€æ · å‘¨æ·±å”±çš„ã€Šæ­Œæ‰‹ã€‹è¿™é¦–æ­Œ\n  [çŸ¥ä¹ä¸Šæœ‰äººé—®] â†’ çŸ¥ä¹ä¸Šæœ‰äººé—®ã€Šæµæµªåœ°çƒã€‹ä¸­ä¸ºä»€ä¹ˆä¸­å›½çš„èˆªå¤©é£èˆ¹çš„é™è½èƒ½åŠ›æ¯”ç¾å›½ä½å¾ˆå¤šå—?ä¸­å›½èˆªå¤©å‘å°„èƒ½åŠ›å’Œç¾å›½æ²¡æœ‰ç›¸åŒä¹‹å¤„ã€‚ä¸­å›½å¯ä»¥è¿™ä¹ˆè¯´ã€‚  è½½äººé£èˆ¹çš„é£è¡Œèƒ½åŠ›æ¯”ç¾å›½é«˜å¾ˆå¤šã€‚ è½½äººèˆªå¤©é£èˆ¹çš„é£è¡Œèƒ½åŠ›æ¯”\n  [ç§‘å­¦æŠ€æœ¯çš„å‘å±•] â†’ ç§‘å­¦æŠ€æœ¯çš„å‘å±•å¦‚ä½•çœ‹å¾…2016å¹´é«˜è€ƒå®Œçº§åé«˜è€ƒæˆç»©æ¯”å¾€å¹´é«˜å‡ºåå‡ åˆ†çš„äººé«˜è¿™ä¹ˆå¤š?è¿˜æ˜¯é«˜åˆ†å¤šäº†? çœ‹åˆ°å¾ˆå¤šé«˜åˆ†è€ƒç”Ÿå¯¹ä½åˆ†è€ƒç”Ÿå—¤ä¹‹ä»¥é¼»ã€‚ å¯¹äº†ä¸€ç‚¹é«˜åˆ†è€ƒç”Ÿå¿ƒé‡Œä¹ŸçŸ¥é“\n==================================================\n\nğŸ“Š Step 8100: loss=4.7331, lr=2.06e-04\nğŸ“Š Step 8200: loss=4.7455, lr=2.03e-04\nğŸ“Š Step 8300: loss=4.7664, lr=2.00e-04\nğŸ“Š Step 8400: loss=4.7452, lr=1.97e-04\nğŸ“Š Step 8500: loss=4.7565, lr=1.95e-04\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\n==================================================\nğŸ“ Step 8500 - ç”Ÿæˆæ ·æœ¬:\n==================================================\n  [ä¸­å›½çš„å†å²] â†’ ä¸­å›½çš„å†å²ç¾å›½ 40 å²çš„äººé€‚åˆç”³è¯·å—?ç¾å›½ç”³è¯·ç¾å›½ç”³è¯·ä¸­å›½å¤§å­¦å‘¢? ç¾å›½æœ¬ç§‘    ç”³è¯·ç¾å›½æœ¬ç§‘  ç¾å›½æœ¬ç§‘   ç¾å›½æœ¬ç§‘  ç¾å›½æœ¬ç§‘    ç¾å›½æœ¬ç§‘   ç¾å›½æœ¬ç§‘   ç¾å›½æœ¬ç§‘\n  [äººå·¥æ™ºèƒ½æ˜¯] â†’ äººå·¥æ™ºèƒ½æ˜¯å¤§å®¶çš„ä½¿ç”¨é¼ æ ‡å«å“ªä¸ªç‰Œå­æ¯”è¾ƒå¥½ç”¨?å“ªä¸ªç‰Œå­æ¯”è¾ƒå¥½ç”¨??æˆ‘æŠŠä½¿ç”¨é¼ æ ‡å«æ¢æˆé¼ æ ‡å«ã€‚ ä½¿ç”¨é¼ æ ‡å«æ—¶åº”è¯¥æ³¨æ„ä¸€ä¸‹ã€‚ è¿™é‡Œé‡ç‚¹è¯´ä¸€ä¸‹ã€‚ åœ¨ä½¿ç”¨æ‰‹æ„Ÿæ—¶è¦æ³¨æ„çœ‹ä¸€ä¸‹ã€‚ å…¶ä¸­çš„éƒ¨ä½\n  [çŸ¥ä¹ä¸Šæœ‰äººé—®] â†’ çŸ¥ä¹ä¸Šæœ‰äººé—®ã€Šä¸‰ä½“ã€‹ä¸ºä»€ä¹ˆæœ‰é‚£ä¹ˆå¤šäººçŸ¥é“å®ƒä¸ºä»€ä¹ˆè¢«é—®è¿‡ä¸ºä»€ä¹ˆä¸è¢«é—®äº†å´å¾ˆå°‘æœ‰äººçŸ¥é“å®ƒè¢«é—®è¿‡å•Š~ ä½†æˆ‘è§‰å¾—å•Š~ ä¸‰ä½“äººé—®è¿™ä¸ªé—®é¢˜çš„æ—¶å€™ä¸æ˜¯æ²¡æœ‰å•Š~ æˆ‘åªèƒ½ç­”ä¸€ä¸‹ã€‚ ä¸‰ä½“äººé—®è¿™æ˜¯\n  [ç§‘å­¦æŠ€æœ¯çš„å‘å±•] â†’ ç§‘å­¦æŠ€æœ¯çš„å‘å±•åšç”µå•†è¿˜æ˜¯åšç”µå•†è¿˜æ˜¯åšç”µå•†è¿˜æ˜¯åšç”µå•†?åšç”µå•†?åšç”µå•†å‘¢?åšç”µå•†å‘¢?åšç”µå•†çš„?åšç”µå•†å‘¢?åšç”µå•†å‘¢?åšç”µå•†å‘¢?åšå¥½ç”µå•†å‘¢?åšç”µå•†å‘¢?åšç”µå•†å‘¢\n==================================================\n\nğŸ“Š Step 8600: loss=4.6765, lr=1.92e-04\nğŸ“Š Step 8700: loss=4.6173, lr=1.89e-04\nğŸ“Š Step 8800: loss=4.6571, lr=1.86e-04\nğŸ“Š Step 8900: loss=4.6869, lr=1.83e-04\nğŸ“Š Step 9000: loss=4.6922, lr=1.81e-04\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\n==================================================\nğŸ“ Step 9000 - ç”Ÿæˆæ ·æœ¬:\n==================================================\n  [ä¸­å›½çš„å†å²] â†’ ä¸­å›½çš„å†å²ä¸ºä»€ä¹ˆåœ¨ 15 å¹´æ²¡æœ‰å–å®Œå•¤é…’åæ‰å¼€å§‹å»å–ä¸­å›½å•¤é…’ ?  \n  [äººå·¥æ™ºèƒ½æ˜¯] â†’ äººå·¥æ™ºèƒ½æ˜¯æœ‰å“ªäº›ç»å…¸çš„ç”µå½±å°è¯è®©ä½ å°è±¡æ·±åˆ»?ä¸ºä»€ä¹ˆæ˜¯ã€Šå°æ—¶ä»£ã€‹é‡Œå¯¼æ¼”çš„ä¸€å¥å°è¯æˆ–è€…å°è¯è®©ä½ å°è±¡æ·±åˆ»ã€‚ ä¸€ã€ã€Šå°æ—¶ä»£ã€‹é‡Œæœ€ç»å…¸çš„å°è¯ æœ‰ä¸€éƒ¨ã€Šå°æ—¶ä»£ã€‹é‡Œæœ€ç»å…¸çš„å°è¯å°±æ˜¯ã€Šå¤§æ—¶ä»£ã€‹\n  [çŸ¥ä¹ä¸Šæœ‰äººé—®] â†’ çŸ¥ä¹ä¸Šæœ‰äººé—®ã€Šé¾™åº”å°ã€‹ä¸ã€Šé¾™åº”å°ã€‹ç›¸æ¯”æœ‰ä½•å¼‚åŒç‚¹?å¦‚ä½•è¯„ä»·ã€Šé¾™åº”å°ã€‹ç¬¬äºŒå­£ç¬¬ä¸€é›†? é¾™åº”å°çš„é€ å‹ä¸ã€Šé¾™åº”å°ã€‹çš„é€ å‹ç›¸æ¯”æœ‰ä½•å¼‚åŒç‚¹? é¾™åº”å°\n  [ç§‘å­¦æŠ€æœ¯çš„å‘å±•] â†’ ç§‘å­¦æŠ€æœ¯çš„å‘å±•ã€Šæµæµªåœ°çƒã€‹ä¸­äººç±»ä¸ºä»€ä¹ˆè¦é€‰æ‹©æ•‘æ´»äººä¸ºæ•‘ç”Ÿè€…æˆ–æœ‰è®¡åˆ’çš„æ•‘ç”Ÿè€…å»æ•‘ç”Ÿè€…ã€‚                        \n==================================================\n\nğŸ“Š Step 9100: loss=4.4941, lr=1.78e-04\nğŸ“Š Step 9200: loss=4.6641, lr=1.75e-04\nğŸ“Š Step 9300: loss=4.5998, lr=1.72e-04\nğŸ“Š Step 9400: loss=4.6729, lr=1.69e-04\nğŸ“Š Step 9500: loss=4.5515, lr=1.66e-04\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\n==================================================\nğŸ“ Step 9500 - ç”Ÿæˆæ ·æœ¬:\n==================================================\n  [ä¸­å›½çš„å†å²] â†’ ä¸­å›½çš„å†å²ã€Šé­”æˆ’ä¸‰éƒ¨æ›²ã€‹ä¸­ç”˜é“å¤«å¯¹ç´¢ä¼¦æœ‰ä½•é‡å¤§çš„è´¡çŒ®? ç”˜é“å¤«æ˜¯å¤§æ³•å¸ˆå‡ºèº« ä»–æ˜¯ä¸€ä¸ªå†å²è§‚äºº ä»–æ˜¯ä¸€ä¸ªå¤§æ³•å¸ˆ é­”æˆ’ä¸‰éƒ¨æ›²æ˜¯å¤§æ³•å¸ˆ ä»–æ˜¯ä¸€ä¸ªæ•…äº‹çš„å¼€ç«¯ ä»–æ˜¯ä¸€ä¸ªå†å²è§‚äºº \n  [äººå·¥æ™ºèƒ½æ˜¯] â†’ äººå·¥æ™ºèƒ½æ˜¯ç¾å›½æœ‰å“ªäº›ä¼˜ç§€çš„ 8 ä½è¯ºè´å°”å¥–è·å¾—è€…å’Œè·å¥–äººéƒ½æœ‰è¿‡å“ªäº›ä¼˜ç§€çš„èƒŒæ™¯ã€è·å¾—æˆå°±ã€è·å¥–ç»å†ã€è·å¥–ç»å†ã€è·å¥–ç»å†ã€è·å¥–ç»å†ã€è·å¥–ç»å†ç­‰ç­‰ã€‚             \n  [çŸ¥ä¹ä¸Šæœ‰äººé—®] â†’ çŸ¥ä¹ä¸Šæœ‰äººé—®å¦‚ä½•è¯„ä»·ã€Šæé™æŒ‘æˆ˜ã€‹ç¬¬äºŒå­£ã€Šæé™æŒ‘æˆ˜ã€‹ä¸­åˆ˜æ¶›çš„å°è¯ã€Œæˆ‘å®æ„¿åƒéº¦å½“åŠ³ã€‚ã€â€”â€”ã€Œåƒéº¦å½“åŠ³ä¹Ÿä¸æ„¿åƒéº¦å½“åŠ³ã€‚ã€â€”â€”ã€Œæˆ‘å®æ„¿åƒéº¦å½“åŠ³ã€‚ã€â€”â€”ã€Œæˆ‘å®æ„¿åƒéº¦å½“åŠ³ã€‚ã€â€”â€”ã€Œ\n  [ç§‘å­¦æŠ€æœ¯çš„å‘å±•] â†’ ç§‘å­¦æŠ€æœ¯çš„å‘å±•å¦‚ä½•è¯„ä»·ç”µå½±ã€Šä¸‰ä½“ã€‹çš„åŸè‘—ä½œè€…åˆ˜æ…ˆæ¬£    \n==================================================\n\nğŸ“Š Step 9600: loss=4.7119, lr=1.63e-04\nğŸ“Š Step 9700: loss=4.6573, lr=1.60e-04\nğŸ“Š Step 9800: loss=4.6211, lr=1.57e-04\nğŸ“Š Step 9900: loss=4.5487, lr=1.54e-04\nğŸ“Š Step 10000: loss=4.6447, lr=1.51e-04\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\n==================================================\nğŸ“ Step 10000 - ç”Ÿæˆæ ·æœ¬:\n==================================================\n  [ä¸­å›½çš„å†å²] â†’ ä¸­å›½çš„å†å²æœ‰å“ªäº›ç‰¹åˆ«æœ‰æ„æ€çš„å†·çŸ¥è¯†å†·çŸ¥è¯†å†·çŸ¥è¯†å†·çŸ¥è¯†å†·çŸ¥è¯†å†·çŸ¥è¯†å†·çŸ¥è¯†å†·çŸ¥è¯†å†·çŸ¥è¯†å†·çŸ¥è¯†å†·çŸ¥è¯†å†·çŸ¥è¯†å†·çŸ¥è¯†å†·çŸ¥è¯†å†·çŸ¥è¯†å†·çŸ¥è¯†å†·çŸ¥è¯†å†·çŸ¥è¯†å†·çŸ¥è¯†å†·çŸ¥è¯†å†·çŸ¥è¯†å†·çŸ¥è¯†å†·çŸ¥è¯†å†·çŸ¥è¯†å†·çŸ¥è¯†å†·çŸ¥è¯†å†·çŸ¥è¯†å†·çŸ¥è¯†å†·çŸ¥è¯†å†·çŸ¥è¯†å†·çŸ¥è¯†å†·çŸ¥è¯†å†·çŸ¥è¯†å†·çŸ¥è¯†å†·çŸ¥è¯†å†·çŸ¥è¯†å†·çŸ¥è¯†å†·çŸ¥è¯†å†·çŸ¥è¯†å†·çŸ¥è¯†å†·çŸ¥è¯†å†·çŸ¥è¯†å†·çŸ¥è¯†å†·çŸ¥è¯†å†·çŸ¥è¯†å†·çŸ¥è¯†å†·çŸ¥è¯†\n  [äººå·¥æ™ºèƒ½æ˜¯] â†’ äººå·¥æ™ºèƒ½æ˜¯ä½ å¬è¿‡æœ€éš¾å¬çš„ä¸€é¦–è¯—æ˜¯ä»€ä¹ˆ? ã€Œå°äººã€\n  [çŸ¥ä¹ä¸Šæœ‰äººé—®] â†’ çŸ¥ä¹ä¸Šæœ‰äººé—®ä¸­å›½é“¶è¡Œé—´å€ºåˆ¸å¸‚åœºå¦‚ä½•è§„èŒƒå€ºåˆ¸æŠ•èµ„è€…çš„å¸‚åœºå®šä»·?å¸‚åœºå®šä»·?\n  [ç§‘å­¦æŠ€æœ¯çš„å‘å±•] â†’ ç§‘å­¦æŠ€æœ¯çš„å‘å±•æ€æ ·è¯„ä»·ç”µå½±ã€Šç½—ç”Ÿé—¨ã€‹çš„çœŸå‡? çœ‹åŸè‘—ã€Šç½—ç”Ÿé—¨ã€‹çš„çœŸå‡ çœ‹åŸè‘—ã€Šç½—ç”Ÿé—¨ã€‹çš„çœŸå‡ çœ‹åŸè‘—åŸè‘—ã€Šç½—ç”Ÿé—¨ã€‹çš„çœŸå‡ çœ‹åŸè‘—åŸè‘—ã€Šç½—ç”Ÿé—¨ã€‹çœŸå‡ çœ‹åŸè‘—ã€Šç½—ç”Ÿé—¨ã€‹çœŸå‡\n==================================================\n\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"from huggingface_hub import snapshot_download\n\n# 1. è®¾ç½®ä½ çš„ä»“åº“ID\nREPO_ID = \"Wilsonwin/gpt2-chinese-mini\" \n\n# 2. å¦‚æœä½ çš„æ–‡ä»¶åƒæˆªå›¾ä¸­é‚£æ ·ï¼Œæ˜¯åœ¨ 'last-checkpoint' è¿™ä¸ªå­æ–‡ä»¶å¤¹é‡Œï¼š\n#    æˆ‘ä»¬éœ€è¦æŠŠè¿™ä¸ªæ–‡ä»¶å¤¹çš„å†…å®¹ä¸‹è½½ä¸‹æ¥\nlocal_checkpoint_path = \"/kaggle/working/downloaded_checkpoint\"\n\nprint(\"â³ æ­£åœ¨ä» Hugging Face ä¸‹è½½ Checkpoint...\")\n\n# ä¸‹è½½æ•´ä¸ªä»“åº“ï¼ˆæˆ–è€…æŒ‡å®šæ–‡ä»¶å¤¹ï¼‰\nsnapshot_download(\n    repo_id=REPO_ID,\n    local_dir=local_checkpoint_path,\n    # å¦‚æœæˆªå›¾é‡Œçš„æ–‡ä»¶ç¡®å®æ˜¯åœ¨ä»“åº“æ ¹ç›®å½•ä¸‹çš„ last-checkpoint æ–‡ä»¶å¤¹é‡Œï¼ŒåŠ ä¸Šä¸‹é¢è¿™è¡Œï¼š\n    # allow_patterns=[\"last-checkpoint/*\"], \n    # ä½†é€šå¸¸å¦‚æœæ˜¯ trainer push çš„ï¼Œç›´æ¥ä¸‹è½½æ•´ä¸ª repo æ ¹ç›®å½•å³å¯ï¼Œä¸éœ€è¦ allow_patterns\n)\n\nprint(f\"âœ… ä¸‹è½½å®Œæˆï¼è·¯å¾„ä½äº: {local_checkpoint_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-03T05:15:02.263821Z","iopub.execute_input":"2026-02-03T05:15:02.264466Z","iopub.status.idle":"2026-02-03T05:16:10.905597Z","shell.execute_reply.started":"2026-02-03T05:15:02.264432Z","shell.execute_reply":"2026-02-03T05:16:10.905035Z"}},"outputs":[{"name":"stdout","text":"â³ æ­£åœ¨ä» Hugging Face ä¸‹è½½ Checkpoint...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Fetching 23 files:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"022f26b32add4218aec19870fac2c7ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"last-checkpoint/model.safetensors:   0%|          | 0.00/272M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4fd5da643cc440fc8f4230a99a04db1f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb11455ea6944aeca737cb312ea64c5c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"last-checkpoint/optimizer.pt:   0%|          | 0.00/290M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ca24f9400574936b4c3bbe06308866b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/132 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c600baac1dcc4f7189b5479537254578"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/774 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fc5ba0bf01c4d369ff5c3c6480eb2fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/774 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92ff6f0c03d6449990a30664184d4965"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/132 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bcf4fa84bbde444d929e743eca2f5e10"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":".gitattributes: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db9ad1e1f19044f8be998cc93b45608c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"last-checkpoint/rng_state.pth:   0%|          | 0.00/14.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df7849a5dc2c42fba88ade77f957799a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"last-checkpoint/scheduler.pt:   0%|          | 0.00/1.47k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2be2d3fb55ae409a91da425493963bfb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"last-checkpoint/scaler.pt:   0%|          | 0.00/1.38k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f14c858269d44159b292ec9ed0bc347"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"last-checkpoint/tokenizer.model:   0%|          | 0.00/735k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8dcd78c4f7c44e31b2edcdcd9027b919"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/552 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2abe6088516a435e87d42b6b3f239126"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"197cbdd30a6b4fbe96cc596119e66e92"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85f2ef4d8cba40cd82722394dc8606f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"trainer_state.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"573641472d1e4ece8026484ec0f68f67"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"last-checkpoint/training_args.bin:   0%|          | 0.00/5.84k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b469cd76a7c3457385677b2f3bbabdd0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/272M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2d47c3c518644449661514bbde5d9a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/735k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a33115df885f42cd979d28fd2893b15f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/552 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da725904eba0438aa2e9be1b1d668751"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63ece2d47a6842e2869a0786fa901118"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"500d57afeaa443e98976b97a804a35d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"training_args.bin:   0%|          | 0.00/5.84k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4204343db8b4ad696eed0f63287c55f"}},"metadata":{}},{"name":"stdout","text":"âœ… ä¸‹è½½å®Œæˆï¼è·¯å¾„ä½äº: /kaggle/working/downloaded_checkpoint\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"**CAUTION**\n\næ–­ç‚¹ç»­è®­: å¦‚æœè®­ç»ƒä¸­æ–­ï¼Œä¸‹æ¬¡è¿è¡Œæ—¶ä½¿ç”¨","metadata":{}},{"cell_type":"code","source":"# 1. ç¡®è®¤è·¯å¾„ï¼šä½ éœ€è¦æŒ‡å‘åŒ…å« config.json å’Œ optimizer.pt çš„é‚£ä¸€å±‚æ–‡ä»¶å¤¹\n# å¦‚æœä½ ä¹‹å‰æ˜¯ç”¨ snapshot_download ä¸‹è½½çš„ï¼Œå¯èƒ½éœ€è¦æ£€æŸ¥ä¸€ä¸‹æ˜¯å¦å¤šäº†ä¸€å±‚æ–‡ä»¶å¤¹\nimport os\n\n# å‡è®¾è¿™æ˜¯ä½ åˆšæ‰ä¸‹è½½çš„ç›®æ ‡ç›®å½•\nchk_path = \"/kaggle/working/downloaded_checkpoint\"\n\n# ğŸ›‘ æ£€æŸ¥ç‚¹ï¼šé˜²æ­¢æ–‡ä»¶å¤¹å¥—å¨ƒ\n# æœ‰æ—¶å€™ä¸‹è½½ä¸‹æ¥æ˜¯ /kaggle/working/downloaded_checkpoint/last-checkpoint/\n# æˆ–è€…æ˜¯ /kaggle/working/downloaded_checkpoint/checkpoint-10000/\n# ä¸‹é¢è¿™æ®µä»£ç å¸®ä½ è‡ªåŠ¨æ‰¾åˆ°åŒ…å« config.json çš„é‚£ä¸€å±‚\nif \"config.json\" not in os.listdir(chk_path):\n    for root, dirs, files in os.walk(chk_path):\n        if \"config.json\" in files:\n            chk_path = root\n            break\n\nprint(f\"ğŸ¯ æœ€ç»ˆé”å®šçš„ Checkpoint è·¯å¾„: {chk_path}\")\n\n# 2. å¼€å§‹ç»­è®­\n# æ³¨æ„ï¼šè¿™é‡Œä¸ç”¨ Trueï¼Œè€Œæ˜¯ç›´æ¥ç”¨è·¯å¾„å­—ç¬¦ä¸²\ntrainer.train(resume_from_checkpoint=chk_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-03T05:42:41.507008Z","iopub.execute_input":"2026-02-03T05:42:41.507386Z","iopub.status.idle":"2026-02-03T05:42:42.552067Z","shell.execute_reply.started":"2026-02-03T05:42:41.507359Z","shell.execute_reply":"2026-02-03T05:42:42.551010Z"}},"outputs":[{"name":"stdout","text":"ğŸ¯ æœ€ç»ˆé”å®šçš„ Checkpoint è·¯å¾„: /kaggle/working/downloaded_checkpoint\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/1194579703.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# 2. å¼€å§‹ç»­è®­\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# æ³¨æ„ï¼šè¿™é‡Œä¸ç”¨ Trueï¼Œè€Œæ˜¯ç›´æ¥ç”¨è·¯å¾„å­—ç¬¦ä¸²\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchk_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2295\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresume_from_checkpoint\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_sagemaker_mp_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_deepspeed_enabled\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_fsdp_enabled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2297\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_from_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2298\u001b[0m             \u001b[0;31m# In case of repeating the find_executable_batch_size, set `self._train_batch_size` properly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2299\u001b[0m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainerState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRAINER_STATE_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_load_from_checkpoint\u001b[0;34m(self, resume_from_checkpoint, model)\u001b[0m\n\u001b[1;32m   2988\u001b[0m                 \u001b[0;31m# release memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2989\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2990\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_issue_warnings_after_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2992\u001b[0m         \u001b[0;31m# Load adapters following PR # 24096\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_issue_warnings_after_load\u001b[0;34m(self, load_result)\u001b[0m\n\u001b[1;32m   3156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_issue_warnings_after_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3157\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3158\u001b[0;31m             if self.model._keys_to_ignore_on_save is not None and set(load_result.missing_keys) == set(\n\u001b[0m\u001b[1;32m   3159\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keys_to_ignore_on_save\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3160\u001b[0m             ):\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1960\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1961\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1962\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   1963\u001b[0m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1964\u001b[0m         )\n","\u001b[0;31mAttributeError\u001b[0m: 'DataParallel' object has no attribute '_keys_to_ignore_on_save'"],"ename":"AttributeError","evalue":"'DataParallel' object has no attribute '_keys_to_ignore_on_save'","output_type":"error"}],"execution_count":22},{"cell_type":"markdown","source":"**5.2 è®­ç»ƒç›‘æ§ä¸è¯Šæ–­**","metadata":{}},{"cell_type":"code","source":"# === Cell 12: è®­ç»ƒè¯Šæ–­ (å¯é€‰ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è¿è¡Œ) ===\n# æŸ¥çœ‹è®­ç»ƒæ—¥å¿—\nimport json\nlog_history = trainer.state.log_history\nif log_history:\n    print(\"ğŸ“Š è®­ç»ƒå†å²:\")\n    for log in log_history[-5:]:  # æœ€è¿‘ 5 æ¡\n        if \"loss\" in log:\n            print(f\"   Step {log.get('step', 'N/A')}: Loss = {log['loss']:.4f}\")\n# ç»˜åˆ¶ Loss æ›²çº¿ (éœ€è¦ matplotlib)\ntry:\n    import matplotlib.pyplot as plt\n    \n    losses = [log[\"loss\"] for log in log_history if \"loss\" in log]\n    steps = [log[\"step\"] for log in log_history if \"loss\" in log]\n    \n    plt.figure(figsize=(10, 4))\n    plt.plot(steps, losses)\n    plt.xlabel(\"Steps\")\n    plt.ylabel(\"Loss\")\n    plt.title(\"Training Loss Curve\")\n    plt.grid(True)\n    plt.savefig(\"/kaggle/working/loss_curve.png\", dpi=100)\n    plt.show()\nexcept ImportError:\n    print(\"matplotlib æœªå®‰è£…ï¼Œè·³è¿‡ç»˜å›¾\")","metadata":{"trusted":true,"execution":{"execution_failed":"2026-02-03T05:00:05.019Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ğŸŒ ç¬¬å…­é˜¶æ®µï¼šHuggingFace Spaces éƒ¨ç½²","metadata":{}},{"cell_type":"markdown","source":"**6.1 åˆ›å»º Space**","metadata":{}},{"cell_type":"markdown","source":"è®¿é—® huggingface.co/spaces\n\nç‚¹å‡» Create new Space\n\né…ç½®:\n\nSpace name: gpt2-chinese-demo\n\nSDK: Gradio\n\nHardware: CPU basic (å…è´¹)\n\nåˆ›å»ºåè¿›å…¥ Files tab","metadata":{}},{"cell_type":"markdown","source":"**6.2 app.py**","metadata":{}},{"cell_type":"code","source":"# === HuggingFace Space: app.py ===\nimport gradio as gr\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nimport torch\n# ğŸ”´ ä¿®æ”¹ä¸ºæ‚¨çš„æ¨¡å‹ ID\nMODEL_ID = \"YOUR_USERNAME/gpt2-chinese-mini\"\nprint(f\"æ­£åœ¨åŠ è½½æ¨¡å‹: {MODEL_ID}\")\ntry:\n    tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n    model = AutoModelForCausalLM.from_pretrained(MODEL_ID)\n    model.eval()\n    print(\"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!\")\nexcept Exception as e:\n    print(f\"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}\")\n    tokenizer = None\n    model = None\ndef generate_text(\n    prompt: str,\n    max_length: int = 150,\n    temperature: float = 0.8,\n    top_k: int = 50,\n    top_p: float = 0.95,\n    num_return_sequences: int = 1,\n) -> str:\n    \"\"\"ç”Ÿæˆæ–‡æœ¬\"\"\"\n    if model is None or tokenizer is None:\n        return \"âŒ æ¨¡å‹æœªåŠ è½½æˆåŠŸï¼Œè¯·æ£€æŸ¥æ¨¡å‹ ID\"\n    \n    if not prompt.strip():\n        return \"è¯·è¾“å…¥æç¤ºæ–‡æœ¬\"\n    \n    try:\n        inputs = tokenizer(prompt, return_tensors=\"pt\")\n        \n        with torch.no_grad():\n            outputs = model.generate(\n                **inputs,\n                max_length=max_length,\n                temperature=temperature,\n                top_k=top_k,\n                top_p=top_p,\n                num_return_sequences=num_return_sequences,\n                do_sample=True,\n                pad_token_id=tokenizer.pad_token_id,\n                eos_token_id=tokenizer.eos_token_id,\n                no_repeat_ngram_size=2,  # å‡å°‘é‡å¤\n            )\n        \n        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n        return generated_text\n    \n    except Exception as e:\n        return f\"ç”Ÿæˆå‡ºé”™: {e}\"\n# === Gradio ç•Œé¢ ===\nwith gr.Blocks(title=\"ä¸­æ–‡ GPT-2 Mini\", theme=gr.themes.Soft()) as demo:\n    gr.Markdown(\"\"\"\n    # ğŸ‡¨ğŸ‡³ ä¸­æ–‡ GPT-2 Mini\n    \n    è¿™æ˜¯ä¸€ä¸ªåœ¨ Kaggle ä¸Šä»é›¶é¢„è®­ç»ƒçš„ä¸­æ–‡è¯­è¨€æ¨¡å‹ã€‚\n    \n    > âš ï¸ **æ³¨æ„**: è¿™æ˜¯ä¸€ä¸ªå°å‹æ¼”ç¤ºæ¨¡å‹ï¼Œç”Ÿæˆè´¨é‡æœ‰é™ï¼Œå¯èƒ½äº§ç”Ÿä¸å‡†ç¡®æˆ–æ— æ„ä¹‰çš„å†…å®¹ã€‚\n    \"\"\")\n    \n    with gr.Row():\n        with gr.Column(scale=2):\n            prompt_input = gr.Textbox(\n                label=\"è¾“å…¥æç¤º\",\n                placeholder=\"ä¾‹å¦‚ï¼šäººå·¥æ™ºèƒ½çš„æœªæ¥å‘å±•\",\n                lines=3,\n            )\n            \n            with gr.Row():\n                max_length = gr.Slider(50, 300, value=150, step=10, label=\"æœ€å¤§é•¿åº¦\")\n                temperature = gr.Slider(0.1, 1.5, value=0.8, step=0.1, label=\"æ¸©åº¦\")\n            \n            with gr.Row():\n                top_k = gr.Slider(10, 100, value=50, step=5, label=\"Top-K\")\n                top_p = gr.Slider(0.5, 1.0, value=0.95, step=0.05, label=\"Top-P\")\n            \n            generate_btn = gr.Button(\"ğŸš€ ç”Ÿæˆ\", variant=\"primary\")\n        \n        with gr.Column(scale=3):\n            output = gr.Textbox(label=\"ç”Ÿæˆç»“æœ\", lines=10)\n    \n    generate_btn.click(\n        fn=generate_text,\n        inputs=[prompt_input, max_length, temperature, top_k, top_p],\n        outputs=output,\n    )\n    \n    gr.Examples(\n        examples=[\n            [\"ä¸­å›½çš„å†å²\"],\n            [\"äººå·¥æ™ºèƒ½æ˜¯\"],\n            [\"ä»Šå¤©å¤©æ°”\"],\n            [\"ç§‘å­¦æŠ€æœ¯çš„å‘å±•\"],\n        ],\n        inputs=prompt_input,\n    )\ndemo.launch()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T19:07:14.513784Z","iopub.status.idle":"2026-02-02T19:07:14.514091Z","shell.execute_reply.started":"2026-02-02T19:07:14.513946Z","shell.execute_reply":"2026-02-02T19:07:14.513964Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**6.3 requirements.txt**","metadata":{}},{"cell_type":"code","source":"transformers>=4.37.0\ntorch>=2.0.0\ngradio>=4.0.0\nsentencepiece","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T19:07:14.514799Z","iopub.status.idle":"2026-02-02T19:07:14.515049Z","shell.execute_reply.started":"2026-02-02T19:07:14.514932Z","shell.execute_reply":"2026-02-02T19:07:14.514947Z"}},"outputs":[],"execution_count":null}]}